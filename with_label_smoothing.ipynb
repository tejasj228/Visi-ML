{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchviz import make_dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Logistic:\n",
    "    def __init__(self, X_train, Y_train, epoch=100, learning_rate=0.01):\n",
    "        self.X_train = X_train\n",
    "        self.Y_train = Y_train\n",
    "        self.epoch = epoch\n",
    "        self.learning_rate = learning_rate\n",
    "        self.Y_train = self.one_hot_encode_with_smoothing(Y_train)\n",
    "        self.num_classes = self.Y_train.shape[1]\n",
    "        self.num_features = self.X_train.shape[1]\n",
    "        self.Weights = np.zeros((self.num_features, self.num_classes))\n",
    "        self.Bias = np.zeros((1, self.num_classes))\n",
    "        self.Weights_array = []\n",
    "        self.Bias_array = []\n",
    "        self.Weights_array.append(self.Weights)\n",
    "        self.Bias_array.append(self.Bias)\n",
    "        self.loss_array = []\n",
    "        self.accuracy_array = []\n",
    "        \n",
    "    def one_hot_encode_with_smoothing(self, Y):\n",
    "        one_hot = np.zeros((Y.size, Y.max() + 1))\n",
    "        one_hot[np.arange(Y.size), Y] = 1\n",
    "        smoothing_parameter = 0.1\n",
    "        one_hot = one_hot * (1 - smoothing_parameter) + smoothing_parameter / one_hot.shape[1]\n",
    "        return one_hot\n",
    "\n",
    "    # ADD BOTH STOCHASTIC AND MINI BATCH GRADIENT DESCENT\n",
    "    def train(self):\n",
    "        for i in range(self.epoch):\n",
    "            # print(f\"Epoch {i+1} begins, value of Weights => {self.Weights}, value of Bias => {self.Bias}\")\n",
    "            activation = self.activation()\n",
    "            # print(f\"Activation => {activation}\")\n",
    "            grad_wrt_W = -np.matmul(self.X_train.T, (self.Y_train - activation))\n",
    "            grad_wrt_B = -np.sum(self.Y_train - activation, axis=0, keepdims=True)\n",
    "\n",
    "            self.Weights -= self.learning_rate * grad_wrt_W\n",
    "            self.Bias -= self.learning_rate * grad_wrt_B\n",
    "\n",
    "            self.Weights_array.append(self.Weights)\n",
    "            self.Bias_array.append(self.Bias)\n",
    "\n",
    "            # print(f\"Epoch {i+1} ends, value of Weights => {self.Weights}, value of Bias => {self.Bias}\")\n",
    "\n",
    "            loss = self.loss(activation)\n",
    "            self.loss_array.append(loss)\n",
    "            accuracy = self.accuracy(activation)\n",
    "            self.accuracy_array.append(accuracy)\n",
    "            print(f\"Epoch : {i+1} || Loss => {loss:.4f} || Accuracy => {accuracy:.4f}\\n----------------------\")\n",
    "\n",
    "    def train_stochastic(self):\n",
    "        for i in range(self.epoch):\n",
    "            for j in range(self.X_train.shape[0]):\n",
    "                activation = self.activation_stochastic(self.X_train[j].reshape(1, -1))\n",
    "                grad_wrt_W = -np.matmul(self.X_train[j].reshape(-1, 1), (self.Y_train[j] - activation))\n",
    "                grad_wrt_B = -np.sum(self.Y_train[j] - activation, axis=0, keepdims=True)\n",
    "\n",
    "                self.Weights -= self.learning_rate * grad_wrt_W\n",
    "                self.Bias -= self.learning_rate * grad_wrt_B\n",
    "\n",
    "            self.Weights_array.append(self.Weights)\n",
    "            self.Bias_array.append(self.Bias)\n",
    "\n",
    "            activation = self.activation()\n",
    "            loss = self.loss(activation)\n",
    "            self.loss_array.append(loss)\n",
    "            accuracy = self.accuracy(activation)\n",
    "            self.accuracy_array.append(accuracy)\n",
    "            print(f\"Epoch : {i+1} || Loss => {loss:.4f} || Accuracy => {accuracy:.4f}\\n----------------------\")\n",
    "\n",
    "    def activation_stochastic(self, X):\n",
    "        linear_model = np.dot(X, self.Weights) + self.Bias\n",
    "        return self.softmax(linear_model)\n",
    "\n",
    "    def activation(self):\n",
    "        linear_model = np.dot(self.X_train, self.Weights) + self.Bias\n",
    "        return self.softmax(linear_model)\n",
    "\n",
    "    def softmax(self, z):\n",
    "        exp_z = np.exp(z - np.max(z, axis=1, keepdims=True))\n",
    "        return exp_z / np.sum(exp_z, axis=1, keepdims=True)\n",
    "\n",
    "    def loss(self, activation):\n",
    "        n = self.Y_train.shape[0]\n",
    "        m = self.Y_train.shape[1]\n",
    "        total = 0\n",
    "        for i in range(n):\n",
    "            for j in range(m):\n",
    "                total += self.Y_train[i, j] * np.log(activation[i, j])\n",
    "        return -total / n\n",
    "                \n",
    "\n",
    "    def accuracy(self, activation):\n",
    "        predictions = np.argmax(activation, axis=1)\n",
    "        actuals = np.argmax(self.Y_train, axis=1)\n",
    "        return np.mean(predictions == actuals)\n",
    "    \n",
    "    def test_accuracy(self, X_test, Y_test):\n",
    "        Y_test = self.one_hot_encode(Y_test)\n",
    "        activation = self.softmax(np.dot(X_test, self.Weights) + self.Bias)\n",
    "        predictions = np.argmax(activation, axis=1)\n",
    "        actuals = np.argmax(Y_test, axis=1)\n",
    "        return np.mean(predictions == actuals)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (50000, 32, 32, 3), Training labels shape: (50000, 1)\n",
      "Test data shape: (10000, 32, 32, 3), Test labels shape: (10000, 1)\n",
      "Epoch : 1 || Loss => 20.9535 || Accuracy => 1.0000\n",
      "----------------------\n",
      "Epoch : 2 || Loss => 20.9535 || Accuracy => 1.0000\n",
      "----------------------\n",
      "Epoch : 3 || Loss => 20.9535 || Accuracy => 1.0000\n",
      "----------------------\n",
      "Epoch : 4 || Loss => 20.9535 || Accuracy => 1.0000\n",
      "----------------------\n",
      "Epoch : 5 || Loss => 20.9535 || Accuracy => 1.0000\n",
      "----------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 17\u001b[0m\n\u001b[0;32m     14\u001b[0m x_test \u001b[38;5;241m=\u001b[39m x_test\u001b[38;5;241m.\u001b[39mreshape((x_test\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m     16\u001b[0m model \u001b[38;5;241m=\u001b[39m Logistic(x_train,y_train,\u001b[38;5;241m10\u001b[39m,\u001b[38;5;241m0.001\u001b[39m)\n\u001b[1;32m---> 17\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_stochastic\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest Accuracy: \u001b[39m\u001b[38;5;124m\"\u001b[39m,model\u001b[38;5;241m.\u001b[39mtest_accuracy(x_test,y_test))\n",
      "Cell \u001b[1;32mIn[3], line 63\u001b[0m, in \u001b[0;36mLogistic.train_stochastic\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mBias_array\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mBias)\n\u001b[0;32m     62\u001b[0m activation \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation()\n\u001b[1;32m---> 63\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mactivation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_array\u001b[38;5;241m.\u001b[39mappend(loss)\n\u001b[0;32m     65\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccuracy(activation)\n",
      "Cell \u001b[1;32mIn[3], line 87\u001b[0m, in \u001b[0;36mLogistic.loss\u001b[1;34m(self, activation)\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n):\n\u001b[0;32m     86\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(m):\n\u001b[1;32m---> 87\u001b[0m         total \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mY_train[i, j] \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mlog(activation[i, j])\n\u001b[0;32m     88\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m-\u001b[39mtotal \u001b[38;5;241m/\u001b[39m n\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "\n",
    "# Load CIFAR-10 dataset\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# Normalize the images to the range [0, 1]\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "print(f\"Training data shape: {x_train.shape}, Training labels shape: {y_train.shape}\")\n",
    "print(f\"Test data shape: {x_test.shape}, Test labels shape: {y_test.shape}\")\n",
    "\n",
    "x_train = x_train.reshape((x_train.shape[0], -1))\n",
    "x_test = x_test.reshape((x_test.shape[0], -1))\n",
    "\n",
    "model = Logistic(x_train,y_train,10,0.001)\n",
    "model.train_stochastic()\n",
    "print(\"Test Accuracy: \",model.test_accuracy(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1 || Loss => 0.8611 || Accuracy => 0.8886\n",
      "----------------------\n",
      "Epoch : 2 || Loss => 0.8414 || Accuracy => 0.8977\n",
      "----------------------\n",
      "Epoch : 3 || Loss => 0.8329 || Accuracy => 0.9018\n",
      "----------------------\n",
      "Epoch : 4 || Loss => 0.8278 || Accuracy => 0.9041\n",
      "----------------------\n",
      "Epoch : 5 || Loss => 0.8243 || Accuracy => 0.9059\n",
      "----------------------\n",
      "Epoch : 6 || Loss => 0.8217 || Accuracy => 0.9068\n",
      "----------------------\n",
      "Epoch : 7 || Loss => 0.8196 || Accuracy => 0.9079\n",
      "----------------------\n",
      "Epoch : 8 || Loss => 0.8180 || Accuracy => 0.9083\n",
      "----------------------\n",
      "Epoch : 9 || Loss => 0.8166 || Accuracy => 0.9088\n",
      "----------------------\n",
      "Epoch : 10 || Loss => 0.8154 || Accuracy => 0.9093\n",
      "----------------------\n",
      "Epoch : 11 || Loss => 0.8144 || Accuracy => 0.9097\n",
      "----------------------\n",
      "Epoch : 12 || Loss => 0.8135 || Accuracy => 0.9103\n",
      "----------------------\n",
      "Epoch : 13 || Loss => 0.8127 || Accuracy => 0.9106\n",
      "----------------------\n",
      "Epoch : 14 || Loss => 0.8120 || Accuracy => 0.9110\n",
      "----------------------\n",
      "Epoch : 15 || Loss => 0.8114 || Accuracy => 0.9112\n",
      "----------------------\n",
      "Epoch : 16 || Loss => 0.8108 || Accuracy => 0.9115\n",
      "----------------------\n",
      "Epoch : 17 || Loss => 0.8103 || Accuracy => 0.9118\n",
      "----------------------\n",
      "Epoch : 18 || Loss => 0.8099 || Accuracy => 0.9119\n",
      "----------------------\n",
      "Epoch : 19 || Loss => 0.8094 || Accuracy => 0.9120\n",
      "----------------------\n",
      "Epoch : 20 || Loss => 0.8090 || Accuracy => 0.9123\n",
      "----------------------\n",
      "Epoch : 21 || Loss => 0.8086 || Accuracy => 0.9124\n",
      "----------------------\n",
      "Epoch : 22 || Loss => 0.8083 || Accuracy => 0.9125\n",
      "----------------------\n",
      "Epoch : 23 || Loss => 0.8080 || Accuracy => 0.9127\n",
      "----------------------\n",
      "Epoch : 24 || Loss => 0.8077 || Accuracy => 0.9128\n",
      "----------------------\n",
      "Epoch : 25 || Loss => 0.8074 || Accuracy => 0.9130\n",
      "----------------------\n",
      "Epoch : 26 || Loss => 0.8071 || Accuracy => 0.9131\n",
      "----------------------\n",
      "Epoch : 27 || Loss => 0.8068 || Accuracy => 0.9131\n",
      "----------------------\n",
      "Epoch : 28 || Loss => 0.8066 || Accuracy => 0.9131\n",
      "----------------------\n",
      "Epoch : 29 || Loss => 0.8064 || Accuracy => 0.9132\n",
      "----------------------\n",
      "Epoch : 30 || Loss => 0.8061 || Accuracy => 0.9133\n",
      "----------------------\n",
      "Epoch : 31 || Loss => 0.8059 || Accuracy => 0.9135\n",
      "----------------------\n",
      "Epoch : 32 || Loss => 0.8057 || Accuracy => 0.9136\n",
      "----------------------\n",
      "Epoch : 33 || Loss => 0.8055 || Accuracy => 0.9136\n",
      "----------------------\n",
      "Epoch : 34 || Loss => 0.8054 || Accuracy => 0.9139\n",
      "----------------------\n",
      "Epoch : 35 || Loss => 0.8052 || Accuracy => 0.9140\n",
      "----------------------\n",
      "Epoch : 36 || Loss => 0.8050 || Accuracy => 0.9141\n",
      "----------------------\n",
      "Epoch : 37 || Loss => 0.8048 || Accuracy => 0.9143\n",
      "----------------------\n",
      "Epoch : 38 || Loss => 0.8047 || Accuracy => 0.9143\n",
      "----------------------\n",
      "Epoch : 39 || Loss => 0.8045 || Accuracy => 0.9145\n",
      "----------------------\n",
      "Epoch : 40 || Loss => 0.8044 || Accuracy => 0.9146\n",
      "----------------------\n",
      "Epoch : 41 || Loss => 0.8043 || Accuracy => 0.9147\n",
      "----------------------\n",
      "Epoch : 42 || Loss => 0.8041 || Accuracy => 0.9147\n",
      "----------------------\n",
      "Epoch : 43 || Loss => 0.8040 || Accuracy => 0.9148\n",
      "----------------------\n",
      "Epoch : 44 || Loss => 0.8039 || Accuracy => 0.9149\n",
      "----------------------\n",
      "Epoch : 45 || Loss => 0.8037 || Accuracy => 0.9149\n",
      "----------------------\n",
      "Epoch : 46 || Loss => 0.8036 || Accuracy => 0.9150\n",
      "----------------------\n",
      "Epoch : 47 || Loss => 0.8035 || Accuracy => 0.9151\n",
      "----------------------\n",
      "Epoch : 48 || Loss => 0.8034 || Accuracy => 0.9152\n",
      "----------------------\n",
      "Epoch : 49 || Loss => 0.8033 || Accuracy => 0.9152\n",
      "----------------------\n",
      "Epoch : 50 || Loss => 0.8032 || Accuracy => 0.9153\n",
      "----------------------\n",
      "Epoch : 51 || Loss => 0.8031 || Accuracy => 0.9154\n",
      "----------------------\n",
      "Epoch : 52 || Loss => 0.8030 || Accuracy => 0.9155\n",
      "----------------------\n",
      "Epoch : 53 || Loss => 0.8029 || Accuracy => 0.9156\n",
      "----------------------\n",
      "Epoch : 54 || Loss => 0.8028 || Accuracy => 0.9156\n",
      "----------------------\n",
      "Epoch : 55 || Loss => 0.8027 || Accuracy => 0.9157\n",
      "----------------------\n",
      "Epoch : 56 || Loss => 0.8026 || Accuracy => 0.9158\n",
      "----------------------\n",
      "Epoch : 57 || Loss => 0.8025 || Accuracy => 0.9159\n",
      "----------------------\n",
      "Epoch : 58 || Loss => 0.8025 || Accuracy => 0.9159\n",
      "----------------------\n",
      "Epoch : 59 || Loss => 0.8024 || Accuracy => 0.9160\n",
      "----------------------\n",
      "Epoch : 60 || Loss => 0.8023 || Accuracy => 0.9160\n",
      "----------------------\n",
      "Epoch : 61 || Loss => 0.8022 || Accuracy => 0.9161\n",
      "----------------------\n",
      "Epoch : 62 || Loss => 0.8021 || Accuracy => 0.9162\n",
      "----------------------\n",
      "Epoch : 63 || Loss => 0.8021 || Accuracy => 0.9163\n",
      "----------------------\n",
      "Epoch : 64 || Loss => 0.8020 || Accuracy => 0.9163\n",
      "----------------------\n",
      "Epoch : 65 || Loss => 0.8019 || Accuracy => 0.9163\n",
      "----------------------\n",
      "Epoch : 66 || Loss => 0.8019 || Accuracy => 0.9163\n",
      "----------------------\n",
      "Epoch : 67 || Loss => 0.8018 || Accuracy => 0.9163\n",
      "----------------------\n",
      "Epoch : 68 || Loss => 0.8017 || Accuracy => 0.9164\n",
      "----------------------\n",
      "Epoch : 69 || Loss => 0.8017 || Accuracy => 0.9164\n",
      "----------------------\n",
      "Epoch : 70 || Loss => 0.8016 || Accuracy => 0.9165\n",
      "----------------------\n",
      "Epoch : 71 || Loss => 0.8015 || Accuracy => 0.9165\n",
      "----------------------\n",
      "Epoch : 72 || Loss => 0.8015 || Accuracy => 0.9165\n",
      "----------------------\n",
      "Epoch : 73 || Loss => 0.8014 || Accuracy => 0.9164\n",
      "----------------------\n",
      "Epoch : 74 || Loss => 0.8014 || Accuracy => 0.9165\n",
      "----------------------\n",
      "Epoch : 75 || Loss => 0.8013 || Accuracy => 0.9165\n",
      "----------------------\n",
      "Epoch : 76 || Loss => 0.8013 || Accuracy => 0.9165\n",
      "----------------------\n",
      "Epoch : 77 || Loss => 0.8012 || Accuracy => 0.9165\n",
      "----------------------\n",
      "Epoch : 78 || Loss => 0.8012 || Accuracy => 0.9166\n",
      "----------------------\n",
      "Epoch : 79 || Loss => 0.8011 || Accuracy => 0.9165\n",
      "----------------------\n",
      "Epoch : 80 || Loss => 0.8011 || Accuracy => 0.9166\n",
      "----------------------\n",
      "Epoch : 81 || Loss => 0.8010 || Accuracy => 0.9165\n",
      "----------------------\n",
      "Epoch : 82 || Loss => 0.8010 || Accuracy => 0.9166\n",
      "----------------------\n",
      "Epoch : 83 || Loss => 0.8009 || Accuracy => 0.9166\n",
      "----------------------\n",
      "Epoch : 84 || Loss => 0.8009 || Accuracy => 0.9166\n",
      "----------------------\n",
      "Epoch : 85 || Loss => 0.8008 || Accuracy => 0.9167\n",
      "----------------------\n",
      "Epoch : 86 || Loss => 0.8008 || Accuracy => 0.9167\n",
      "----------------------\n",
      "Epoch : 87 || Loss => 0.8007 || Accuracy => 0.9167\n",
      "----------------------\n",
      "Epoch : 88 || Loss => 0.8007 || Accuracy => 0.9167\n",
      "----------------------\n",
      "Epoch : 89 || Loss => 0.8006 || Accuracy => 0.9167\n",
      "----------------------\n",
      "Epoch : 90 || Loss => 0.8006 || Accuracy => 0.9167\n",
      "----------------------\n",
      "Epoch : 91 || Loss => 0.8005 || Accuracy => 0.9167\n",
      "----------------------\n",
      "Epoch : 92 || Loss => 0.8005 || Accuracy => 0.9167\n",
      "----------------------\n",
      "Epoch : 93 || Loss => 0.8005 || Accuracy => 0.9167\n",
      "----------------------\n",
      "Epoch : 94 || Loss => 0.8004 || Accuracy => 0.9167\n",
      "----------------------\n",
      "Epoch : 95 || Loss => 0.8004 || Accuracy => 0.9168\n",
      "----------------------\n",
      "Epoch : 96 || Loss => 0.8003 || Accuracy => 0.9167\n",
      "----------------------\n",
      "Epoch : 97 || Loss => 0.8003 || Accuracy => 0.9167\n",
      "----------------------\n",
      "Epoch : 98 || Loss => 0.8003 || Accuracy => 0.9167\n",
      "----------------------\n",
      "Epoch : 99 || Loss => 0.8002 || Accuracy => 0.9168\n",
      "----------------------\n",
      "Epoch : 100 || Loss => 0.8002 || Accuracy => 0.9168\n",
      "----------------------\n",
      "Epoch : 101 || Loss => 0.8002 || Accuracy => 0.9169\n",
      "----------------------\n",
      "Epoch : 102 || Loss => 0.8001 || Accuracy => 0.9169\n",
      "----------------------\n",
      "Epoch : 103 || Loss => 0.8001 || Accuracy => 0.9169\n",
      "----------------------\n",
      "Epoch : 104 || Loss => 0.8001 || Accuracy => 0.9169\n",
      "----------------------\n",
      "Epoch : 105 || Loss => 0.8000 || Accuracy => 0.9169\n",
      "----------------------\n",
      "Epoch : 106 || Loss => 0.8000 || Accuracy => 0.9169\n",
      "----------------------\n",
      "Epoch : 107 || Loss => 0.8000 || Accuracy => 0.9169\n",
      "----------------------\n",
      "Epoch : 108 || Loss => 0.7999 || Accuracy => 0.9170\n",
      "----------------------\n",
      "Epoch : 109 || Loss => 0.7999 || Accuracy => 0.9169\n",
      "----------------------\n",
      "Epoch : 110 || Loss => 0.7999 || Accuracy => 0.9169\n",
      "----------------------\n",
      "Epoch : 111 || Loss => 0.7998 || Accuracy => 0.9170\n",
      "----------------------\n",
      "Epoch : 112 || Loss => 0.7998 || Accuracy => 0.9169\n",
      "----------------------\n",
      "Epoch : 113 || Loss => 0.7998 || Accuracy => 0.9169\n",
      "----------------------\n",
      "Epoch : 114 || Loss => 0.7997 || Accuracy => 0.9169\n",
      "----------------------\n",
      "Epoch : 115 || Loss => 0.7997 || Accuracy => 0.9169\n",
      "----------------------\n",
      "Epoch : 116 || Loss => 0.7997 || Accuracy => 0.9169\n",
      "----------------------\n",
      "Epoch : 117 || Loss => 0.7997 || Accuracy => 0.9169\n",
      "----------------------\n",
      "Epoch : 118 || Loss => 0.7996 || Accuracy => 0.9169\n",
      "----------------------\n",
      "Epoch : 119 || Loss => 0.7996 || Accuracy => 0.9169\n",
      "----------------------\n",
      "Epoch : 120 || Loss => 0.7996 || Accuracy => 0.9169\n",
      "----------------------\n",
      "Epoch : 121 || Loss => 0.7995 || Accuracy => 0.9169\n",
      "----------------------\n",
      "Epoch : 122 || Loss => 0.7995 || Accuracy => 0.9169\n",
      "----------------------\n",
      "Epoch : 123 || Loss => 0.7995 || Accuracy => 0.9169\n",
      "----------------------\n",
      "Epoch : 124 || Loss => 0.7995 || Accuracy => 0.9170\n",
      "----------------------\n",
      "Epoch : 125 || Loss => 0.7994 || Accuracy => 0.9170\n",
      "----------------------\n",
      "Epoch : 126 || Loss => 0.7994 || Accuracy => 0.9170\n",
      "----------------------\n",
      "Epoch : 127 || Loss => 0.7994 || Accuracy => 0.9171\n",
      "----------------------\n",
      "Epoch : 128 || Loss => 0.7994 || Accuracy => 0.9171\n",
      "----------------------\n",
      "Epoch : 129 || Loss => 0.7993 || Accuracy => 0.9171\n",
      "----------------------\n",
      "Epoch : 130 || Loss => 0.7993 || Accuracy => 0.9171\n",
      "----------------------\n",
      "Epoch : 131 || Loss => 0.7993 || Accuracy => 0.9172\n",
      "----------------------\n",
      "Epoch : 132 || Loss => 0.7993 || Accuracy => 0.9172\n",
      "----------------------\n",
      "Epoch : 133 || Loss => 0.7992 || Accuracy => 0.9172\n",
      "----------------------\n",
      "Epoch : 134 || Loss => 0.7992 || Accuracy => 0.9172\n",
      "----------------------\n",
      "Epoch : 135 || Loss => 0.7992 || Accuracy => 0.9173\n",
      "----------------------\n",
      "Epoch : 136 || Loss => 0.7992 || Accuracy => 0.9173\n",
      "----------------------\n",
      "Epoch : 137 || Loss => 0.7991 || Accuracy => 0.9173\n",
      "----------------------\n",
      "Epoch : 138 || Loss => 0.7991 || Accuracy => 0.9173\n",
      "----------------------\n",
      "Epoch : 139 || Loss => 0.7991 || Accuracy => 0.9173\n",
      "----------------------\n",
      "Epoch : 140 || Loss => 0.7991 || Accuracy => 0.9173\n",
      "----------------------\n",
      "Epoch : 141 || Loss => 0.7991 || Accuracy => 0.9174\n",
      "----------------------\n",
      "Epoch : 142 || Loss => 0.7990 || Accuracy => 0.9174\n",
      "----------------------\n",
      "Epoch : 143 || Loss => 0.7990 || Accuracy => 0.9174\n",
      "----------------------\n",
      "Epoch : 144 || Loss => 0.7990 || Accuracy => 0.9174\n",
      "----------------------\n",
      "Epoch : 145 || Loss => 0.7990 || Accuracy => 0.9174\n",
      "----------------------\n",
      "Epoch : 146 || Loss => 0.7990 || Accuracy => 0.9174\n",
      "----------------------\n",
      "Epoch : 147 || Loss => 0.7989 || Accuracy => 0.9174\n",
      "----------------------\n",
      "Epoch : 148 || Loss => 0.7989 || Accuracy => 0.9174\n",
      "----------------------\n",
      "Epoch : 149 || Loss => 0.7989 || Accuracy => 0.9175\n",
      "----------------------\n",
      "Epoch : 150 || Loss => 0.7989 || Accuracy => 0.9174\n",
      "----------------------\n",
      "Epoch : 151 || Loss => 0.7989 || Accuracy => 0.9174\n",
      "----------------------\n",
      "Epoch : 152 || Loss => 0.7988 || Accuracy => 0.9175\n",
      "----------------------\n",
      "Epoch : 153 || Loss => 0.7988 || Accuracy => 0.9175\n",
      "----------------------\n",
      "Epoch : 154 || Loss => 0.7988 || Accuracy => 0.9175\n",
      "----------------------\n",
      "Epoch : 155 || Loss => 0.7988 || Accuracy => 0.9175\n",
      "----------------------\n",
      "Epoch : 156 || Loss => 0.7988 || Accuracy => 0.9176\n",
      "----------------------\n",
      "Epoch : 157 || Loss => 0.7987 || Accuracy => 0.9176\n",
      "----------------------\n",
      "Epoch : 158 || Loss => 0.7987 || Accuracy => 0.9176\n",
      "----------------------\n",
      "Epoch : 159 || Loss => 0.7987 || Accuracy => 0.9176\n",
      "----------------------\n",
      "Epoch : 160 || Loss => 0.7987 || Accuracy => 0.9176\n",
      "----------------------\n",
      "Epoch : 161 || Loss => 0.7987 || Accuracy => 0.9176\n",
      "----------------------\n",
      "Epoch : 162 || Loss => 0.7987 || Accuracy => 0.9176\n",
      "----------------------\n",
      "Epoch : 163 || Loss => 0.7986 || Accuracy => 0.9176\n",
      "----------------------\n",
      "Epoch : 164 || Loss => 0.7986 || Accuracy => 0.9177\n",
      "----------------------\n",
      "Epoch : 165 || Loss => 0.7986 || Accuracy => 0.9177\n",
      "----------------------\n",
      "Epoch : 166 || Loss => 0.7986 || Accuracy => 0.9177\n",
      "----------------------\n",
      "Epoch : 167 || Loss => 0.7986 || Accuracy => 0.9177\n",
      "----------------------\n",
      "Epoch : 168 || Loss => 0.7986 || Accuracy => 0.9177\n",
      "----------------------\n",
      "Epoch : 169 || Loss => 0.7985 || Accuracy => 0.9177\n",
      "----------------------\n",
      "Epoch : 170 || Loss => 0.7985 || Accuracy => 0.9177\n",
      "----------------------\n",
      "Epoch : 171 || Loss => 0.7985 || Accuracy => 0.9177\n",
      "----------------------\n",
      "Epoch : 172 || Loss => 0.7985 || Accuracy => 0.9178\n",
      "----------------------\n",
      "Epoch : 173 || Loss => 0.7985 || Accuracy => 0.9178\n",
      "----------------------\n",
      "Epoch : 174 || Loss => 0.7985 || Accuracy => 0.9178\n",
      "----------------------\n",
      "Epoch : 175 || Loss => 0.7984 || Accuracy => 0.9179\n",
      "----------------------\n",
      "Epoch : 176 || Loss => 0.7984 || Accuracy => 0.9178\n",
      "----------------------\n",
      "Epoch : 177 || Loss => 0.7984 || Accuracy => 0.9178\n",
      "----------------------\n",
      "Epoch : 178 || Loss => 0.7984 || Accuracy => 0.9178\n",
      "----------------------\n",
      "Epoch : 179 || Loss => 0.7984 || Accuracy => 0.9178\n",
      "----------------------\n",
      "Epoch : 180 || Loss => 0.7984 || Accuracy => 0.9178\n",
      "----------------------\n",
      "Epoch : 181 || Loss => 0.7984 || Accuracy => 0.9177\n",
      "----------------------\n",
      "Epoch : 182 || Loss => 0.7983 || Accuracy => 0.9177\n",
      "----------------------\n",
      "Epoch : 183 || Loss => 0.7983 || Accuracy => 0.9177\n",
      "----------------------\n",
      "Epoch : 184 || Loss => 0.7983 || Accuracy => 0.9177\n",
      "----------------------\n",
      "Epoch : 185 || Loss => 0.7983 || Accuracy => 0.9178\n",
      "----------------------\n",
      "Epoch : 186 || Loss => 0.7983 || Accuracy => 0.9178\n",
      "----------------------\n",
      "Epoch : 187 || Loss => 0.7983 || Accuracy => 0.9178\n",
      "----------------------\n",
      "Epoch : 188 || Loss => 0.7982 || Accuracy => 0.9178\n",
      "----------------------\n",
      "Epoch : 189 || Loss => 0.7982 || Accuracy => 0.9178\n",
      "----------------------\n",
      "Epoch : 190 || Loss => 0.7982 || Accuracy => 0.9179\n",
      "----------------------\n",
      "Epoch : 191 || Loss => 0.7982 || Accuracy => 0.9179\n",
      "----------------------\n",
      "Epoch : 192 || Loss => 0.7982 || Accuracy => 0.9179\n",
      "----------------------\n",
      "Epoch : 193 || Loss => 0.7982 || Accuracy => 0.9179\n",
      "----------------------\n",
      "Epoch : 194 || Loss => 0.7982 || Accuracy => 0.9179\n",
      "----------------------\n",
      "Epoch : 195 || Loss => 0.7982 || Accuracy => 0.9179\n",
      "----------------------\n",
      "Epoch : 196 || Loss => 0.7981 || Accuracy => 0.9178\n",
      "----------------------\n",
      "Epoch : 197 || Loss => 0.7981 || Accuracy => 0.9178\n",
      "----------------------\n",
      "Epoch : 198 || Loss => 0.7981 || Accuracy => 0.9179\n",
      "----------------------\n",
      "Epoch : 199 || Loss => 0.7981 || Accuracy => 0.9179\n",
      "----------------------\n",
      "Epoch : 200 || Loss => 0.7981 || Accuracy => 0.9179\n",
      "----------------------\n",
      "Epoch : 201 || Loss => 0.7981 || Accuracy => 0.9179\n",
      "----------------------\n",
      "Epoch : 202 || Loss => 0.7981 || Accuracy => 0.9179\n",
      "----------------------\n",
      "Epoch : 203 || Loss => 0.7981 || Accuracy => 0.9179\n",
      "----------------------\n",
      "Epoch : 204 || Loss => 0.7980 || Accuracy => 0.9179\n",
      "----------------------\n",
      "Epoch : 205 || Loss => 0.7980 || Accuracy => 0.9179\n",
      "----------------------\n",
      "Epoch : 206 || Loss => 0.7980 || Accuracy => 0.9179\n",
      "----------------------\n",
      "Epoch : 207 || Loss => 0.7980 || Accuracy => 0.9179\n",
      "----------------------\n",
      "Epoch : 208 || Loss => 0.7980 || Accuracy => 0.9179\n",
      "----------------------\n",
      "Epoch : 209 || Loss => 0.7980 || Accuracy => 0.9179\n",
      "----------------------\n",
      "Epoch : 210 || Loss => 0.7980 || Accuracy => 0.9179\n",
      "----------------------\n",
      "Epoch : 211 || Loss => 0.7980 || Accuracy => 0.9179\n",
      "----------------------\n",
      "Epoch : 212 || Loss => 0.7979 || Accuracy => 0.9180\n",
      "----------------------\n",
      "Epoch : 213 || Loss => 0.7979 || Accuracy => 0.9180\n",
      "----------------------\n",
      "Epoch : 214 || Loss => 0.7979 || Accuracy => 0.9180\n",
      "----------------------\n",
      "Epoch : 215 || Loss => 0.7979 || Accuracy => 0.9179\n",
      "----------------------\n",
      "Epoch : 216 || Loss => 0.7979 || Accuracy => 0.9179\n",
      "----------------------\n",
      "Epoch : 217 || Loss => 0.7979 || Accuracy => 0.9179\n",
      "----------------------\n",
      "Epoch : 218 || Loss => 0.7979 || Accuracy => 0.9179\n",
      "----------------------\n",
      "Epoch : 219 || Loss => 0.7979 || Accuracy => 0.9179\n",
      "----------------------\n",
      "Epoch : 220 || Loss => 0.7979 || Accuracy => 0.9179\n",
      "----------------------\n",
      "Epoch : 221 || Loss => 0.7978 || Accuracy => 0.9179\n",
      "----------------------\n",
      "Epoch : 222 || Loss => 0.7978 || Accuracy => 0.9179\n",
      "----------------------\n",
      "Epoch : 223 || Loss => 0.7978 || Accuracy => 0.9178\n",
      "----------------------\n",
      "Epoch : 224 || Loss => 0.7978 || Accuracy => 0.9178\n",
      "----------------------\n",
      "Epoch : 225 || Loss => 0.7978 || Accuracy => 0.9178\n",
      "----------------------\n",
      "Epoch : 226 || Loss => 0.7978 || Accuracy => 0.9178\n",
      "----------------------\n",
      "Epoch : 227 || Loss => 0.7978 || Accuracy => 0.9178\n",
      "----------------------\n",
      "Epoch : 228 || Loss => 0.7978 || Accuracy => 0.9178\n",
      "----------------------\n",
      "Epoch : 229 || Loss => 0.7978 || Accuracy => 0.9178\n",
      "----------------------\n",
      "Epoch : 230 || Loss => 0.7977 || Accuracy => 0.9179\n",
      "----------------------\n",
      "Epoch : 231 || Loss => 0.7977 || Accuracy => 0.9179\n",
      "----------------------\n",
      "Epoch : 232 || Loss => 0.7977 || Accuracy => 0.9179\n",
      "----------------------\n",
      "Epoch : 233 || Loss => 0.7977 || Accuracy => 0.9178\n",
      "----------------------\n",
      "Epoch : 234 || Loss => 0.7977 || Accuracy => 0.9178\n",
      "----------------------\n",
      "Epoch : 235 || Loss => 0.7977 || Accuracy => 0.9178\n",
      "----------------------\n",
      "Epoch : 236 || Loss => 0.7977 || Accuracy => 0.9178\n",
      "----------------------\n",
      "Epoch : 237 || Loss => 0.7977 || Accuracy => 0.9178\n",
      "----------------------\n",
      "Epoch : 238 || Loss => 0.7977 || Accuracy => 0.9179\n",
      "----------------------\n",
      "Epoch : 239 || Loss => 0.7977 || Accuracy => 0.9178\n",
      "----------------------\n",
      "Epoch : 240 || Loss => 0.7976 || Accuracy => 0.9179\n",
      "----------------------\n",
      "Epoch : 241 || Loss => 0.7976 || Accuracy => 0.9179\n",
      "----------------------\n",
      "Epoch : 242 || Loss => 0.7976 || Accuracy => 0.9178\n",
      "----------------------\n",
      "Epoch : 243 || Loss => 0.7976 || Accuracy => 0.9179\n",
      "----------------------\n",
      "Epoch : 244 || Loss => 0.7976 || Accuracy => 0.9179\n",
      "----------------------\n",
      "Epoch : 245 || Loss => 0.7976 || Accuracy => 0.9179\n",
      "----------------------\n",
      "Epoch : 246 || Loss => 0.7976 || Accuracy => 0.9179\n",
      "----------------------\n",
      "Epoch : 247 || Loss => 0.7976 || Accuracy => 0.9179\n",
      "----------------------\n",
      "Epoch : 248 || Loss => 0.7976 || Accuracy => 0.9179\n",
      "----------------------\n",
      "Epoch : 249 || Loss => 0.7976 || Accuracy => 0.9178\n",
      "----------------------\n",
      "Epoch : 250 || Loss => 0.7975 || Accuracy => 0.9178\n",
      "----------------------\n",
      "Epoch : 251 || Loss => 0.7975 || Accuracy => 0.9178\n",
      "----------------------\n",
      "Epoch : 252 || Loss => 0.7975 || Accuracy => 0.9178\n",
      "----------------------\n",
      "Epoch : 253 || Loss => 0.7975 || Accuracy => 0.9178\n",
      "----------------------\n",
      "Epoch : 254 || Loss => 0.7975 || Accuracy => 0.9178\n",
      "----------------------\n",
      "Epoch : 255 || Loss => 0.7975 || Accuracy => 0.9178\n",
      "----------------------\n",
      "Epoch : 256 || Loss => 0.7975 || Accuracy => 0.9178\n",
      "----------------------\n",
      "Epoch : 257 || Loss => 0.7975 || Accuracy => 0.9178\n",
      "----------------------\n",
      "Epoch : 258 || Loss => 0.7975 || Accuracy => 0.9178\n",
      "----------------------\n",
      "Epoch : 259 || Loss => 0.7975 || Accuracy => 0.9178\n",
      "----------------------\n",
      "Epoch : 260 || Loss => 0.7975 || Accuracy => 0.9178\n",
      "----------------------\n",
      "Epoch : 261 || Loss => 0.7975 || Accuracy => 0.9178\n",
      "----------------------\n",
      "Epoch : 262 || Loss => 0.7974 || Accuracy => 0.9179\n",
      "----------------------\n",
      "Epoch : 263 || Loss => 0.7974 || Accuracy => 0.9179\n",
      "----------------------\n",
      "Epoch : 264 || Loss => 0.7974 || Accuracy => 0.9179\n",
      "----------------------\n",
      "Epoch : 265 || Loss => 0.7974 || Accuracy => 0.9179\n",
      "----------------------\n",
      "Epoch : 266 || Loss => 0.7974 || Accuracy => 0.9179\n",
      "----------------------\n",
      "Epoch : 267 || Loss => 0.7974 || Accuracy => 0.9179\n",
      "----------------------\n",
      "Epoch : 268 || Loss => 0.7974 || Accuracy => 0.9179\n",
      "----------------------\n",
      "Epoch : 269 || Loss => 0.7974 || Accuracy => 0.9179\n",
      "----------------------\n",
      "Epoch : 270 || Loss => 0.7974 || Accuracy => 0.9179\n",
      "----------------------\n",
      "Epoch : 271 || Loss => 0.7974 || Accuracy => 0.9179\n",
      "----------------------\n",
      "Epoch : 272 || Loss => 0.7974 || Accuracy => 0.9179\n",
      "----------------------\n",
      "Epoch : 273 || Loss => 0.7974 || Accuracy => 0.9179\n",
      "----------------------\n",
      "Epoch : 274 || Loss => 0.7973 || Accuracy => 0.9179\n",
      "----------------------\n",
      "Epoch : 275 || Loss => 0.7973 || Accuracy => 0.9179\n",
      "----------------------\n",
      "Epoch : 276 || Loss => 0.7973 || Accuracy => 0.9179\n",
      "----------------------\n",
      "Epoch : 277 || Loss => 0.7973 || Accuracy => 0.9179\n",
      "----------------------\n",
      "Epoch : 278 || Loss => 0.7973 || Accuracy => 0.9179\n",
      "----------------------\n",
      "Epoch : 279 || Loss => 0.7973 || Accuracy => 0.9179\n",
      "----------------------\n",
      "Epoch : 280 || Loss => 0.7973 || Accuracy => 0.9179\n",
      "----------------------\n",
      "Epoch : 281 || Loss => 0.7973 || Accuracy => 0.9179\n",
      "----------------------\n",
      "Epoch : 282 || Loss => 0.7973 || Accuracy => 0.9179\n",
      "----------------------\n",
      "Epoch : 283 || Loss => 0.7973 || Accuracy => 0.9179\n",
      "----------------------\n",
      "Epoch : 284 || Loss => 0.7973 || Accuracy => 0.9180\n",
      "----------------------\n",
      "Epoch : 285 || Loss => 0.7973 || Accuracy => 0.9180\n",
      "----------------------\n",
      "Epoch : 286 || Loss => 0.7973 || Accuracy => 0.9179\n",
      "----------------------\n",
      "Epoch : 287 || Loss => 0.7972 || Accuracy => 0.9179\n",
      "----------------------\n",
      "Epoch : 288 || Loss => 0.7972 || Accuracy => 0.9180\n",
      "----------------------\n",
      "Epoch : 289 || Loss => 0.7972 || Accuracy => 0.9179\n",
      "----------------------\n",
      "Epoch : 290 || Loss => 0.7972 || Accuracy => 0.9179\n",
      "----------------------\n",
      "Epoch : 291 || Loss => 0.7972 || Accuracy => 0.9179\n",
      "----------------------\n",
      "Epoch : 292 || Loss => 0.7972 || Accuracy => 0.9180\n",
      "----------------------\n",
      "Epoch : 293 || Loss => 0.7972 || Accuracy => 0.9180\n",
      "----------------------\n",
      "Epoch : 294 || Loss => 0.7972 || Accuracy => 0.9180\n",
      "----------------------\n",
      "Epoch : 295 || Loss => 0.7972 || Accuracy => 0.9180\n",
      "----------------------\n",
      "Epoch : 296 || Loss => 0.7972 || Accuracy => 0.9180\n",
      "----------------------\n",
      "Epoch : 297 || Loss => 0.7972 || Accuracy => 0.9180\n",
      "----------------------\n",
      "Epoch : 298 || Loss => 0.7972 || Accuracy => 0.9180\n",
      "----------------------\n",
      "Epoch : 299 || Loss => 0.7972 || Accuracy => 0.9180\n",
      "----------------------\n",
      "Epoch : 300 || Loss => 0.7971 || Accuracy => 0.9180\n",
      "----------------------\n",
      "Epoch : 301 || Loss => 0.7971 || Accuracy => 0.9180\n",
      "----------------------\n",
      "Epoch : 302 || Loss => 0.7971 || Accuracy => 0.9180\n",
      "----------------------\n",
      "Epoch : 303 || Loss => 0.7971 || Accuracy => 0.9180\n",
      "----------------------\n",
      "Epoch : 304 || Loss => 0.7971 || Accuracy => 0.9181\n",
      "----------------------\n",
      "Epoch : 305 || Loss => 0.7971 || Accuracy => 0.9180\n",
      "----------------------\n",
      "Epoch : 306 || Loss => 0.7971 || Accuracy => 0.9180\n",
      "----------------------\n",
      "Epoch : 307 || Loss => 0.7971 || Accuracy => 0.9181\n",
      "----------------------\n",
      "Epoch : 308 || Loss => 0.7971 || Accuracy => 0.9181\n",
      "----------------------\n",
      "Epoch : 309 || Loss => 0.7971 || Accuracy => 0.9181\n",
      "----------------------\n",
      "Epoch : 310 || Loss => 0.7971 || Accuracy => 0.9181\n",
      "----------------------\n",
      "Epoch : 311 || Loss => 0.7971 || Accuracy => 0.9181\n",
      "----------------------\n",
      "Epoch : 312 || Loss => 0.7971 || Accuracy => 0.9180\n",
      "----------------------\n",
      "Epoch : 313 || Loss => 0.7971 || Accuracy => 0.9180\n",
      "----------------------\n",
      "Epoch : 314 || Loss => 0.7971 || Accuracy => 0.9180\n",
      "----------------------\n",
      "Epoch : 315 || Loss => 0.7970 || Accuracy => 0.9180\n",
      "----------------------\n",
      "Epoch : 316 || Loss => 0.7970 || Accuracy => 0.9180\n",
      "----------------------\n",
      "Epoch : 317 || Loss => 0.7970 || Accuracy => 0.9180\n",
      "----------------------\n",
      "Epoch : 318 || Loss => 0.7970 || Accuracy => 0.9180\n",
      "----------------------\n",
      "Epoch : 319 || Loss => 0.7970 || Accuracy => 0.9180\n",
      "----------------------\n",
      "Epoch : 320 || Loss => 0.7970 || Accuracy => 0.9180\n",
      "----------------------\n",
      "Epoch : 321 || Loss => 0.7970 || Accuracy => 0.9181\n",
      "----------------------\n",
      "Epoch : 322 || Loss => 0.7970 || Accuracy => 0.9181\n",
      "----------------------\n",
      "Epoch : 323 || Loss => 0.7970 || Accuracy => 0.9181\n",
      "----------------------\n",
      "Epoch : 324 || Loss => 0.7970 || Accuracy => 0.9181\n",
      "----------------------\n",
      "Epoch : 325 || Loss => 0.7970 || Accuracy => 0.9182\n",
      "----------------------\n",
      "Epoch : 326 || Loss => 0.7970 || Accuracy => 0.9182\n",
      "----------------------\n",
      "Epoch : 327 || Loss => 0.7970 || Accuracy => 0.9182\n",
      "----------------------\n",
      "Epoch : 328 || Loss => 0.7970 || Accuracy => 0.9182\n",
      "----------------------\n",
      "Epoch : 329 || Loss => 0.7970 || Accuracy => 0.9182\n",
      "----------------------\n",
      "Epoch : 330 || Loss => 0.7970 || Accuracy => 0.9182\n",
      "----------------------\n",
      "Epoch : 331 || Loss => 0.7969 || Accuracy => 0.9182\n",
      "----------------------\n",
      "Epoch : 332 || Loss => 0.7969 || Accuracy => 0.9182\n",
      "----------------------\n",
      "Epoch : 333 || Loss => 0.7969 || Accuracy => 0.9182\n",
      "----------------------\n",
      "Epoch : 334 || Loss => 0.7969 || Accuracy => 0.9182\n",
      "----------------------\n",
      "Epoch : 335 || Loss => 0.7969 || Accuracy => 0.9182\n",
      "----------------------\n",
      "Epoch : 336 || Loss => 0.7969 || Accuracy => 0.9182\n",
      "----------------------\n",
      "Epoch : 337 || Loss => 0.7969 || Accuracy => 0.9182\n",
      "----------------------\n",
      "Epoch : 338 || Loss => 0.7969 || Accuracy => 0.9182\n",
      "----------------------\n",
      "Epoch : 339 || Loss => 0.7969 || Accuracy => 0.9182\n",
      "----------------------\n",
      "Epoch : 340 || Loss => 0.7969 || Accuracy => 0.9182\n",
      "----------------------\n",
      "Epoch : 341 || Loss => 0.7969 || Accuracy => 0.9182\n",
      "----------------------\n",
      "Epoch : 342 || Loss => 0.7969 || Accuracy => 0.9182\n",
      "----------------------\n",
      "Epoch : 343 || Loss => 0.7969 || Accuracy => 0.9182\n",
      "----------------------\n",
      "Epoch : 344 || Loss => 0.7969 || Accuracy => 0.9182\n",
      "----------------------\n",
      "Epoch : 345 || Loss => 0.7969 || Accuracy => 0.9182\n",
      "----------------------\n",
      "Epoch : 346 || Loss => 0.7969 || Accuracy => 0.9182\n",
      "----------------------\n",
      "Epoch : 347 || Loss => 0.7969 || Accuracy => 0.9182\n",
      "----------------------\n",
      "Epoch : 348 || Loss => 0.7968 || Accuracy => 0.9182\n",
      "----------------------\n",
      "Epoch : 349 || Loss => 0.7968 || Accuracy => 0.9182\n",
      "----------------------\n",
      "Epoch : 350 || Loss => 0.7968 || Accuracy => 0.9182\n",
      "----------------------\n",
      "Epoch : 351 || Loss => 0.7968 || Accuracy => 0.9182\n",
      "----------------------\n",
      "Epoch : 352 || Loss => 0.7968 || Accuracy => 0.9182\n",
      "----------------------\n",
      "Epoch : 353 || Loss => 0.7968 || Accuracy => 0.9182\n",
      "----------------------\n",
      "Epoch : 354 || Loss => 0.7968 || Accuracy => 0.9183\n",
      "----------------------\n",
      "Epoch : 355 || Loss => 0.7968 || Accuracy => 0.9183\n",
      "----------------------\n",
      "Epoch : 356 || Loss => 0.7968 || Accuracy => 0.9183\n",
      "----------------------\n",
      "Epoch : 357 || Loss => 0.7968 || Accuracy => 0.9183\n",
      "----------------------\n",
      "Epoch : 358 || Loss => 0.7968 || Accuracy => 0.9182\n",
      "----------------------\n",
      "Epoch : 359 || Loss => 0.7968 || Accuracy => 0.9183\n",
      "----------------------\n",
      "Epoch : 360 || Loss => 0.7968 || Accuracy => 0.9183\n",
      "----------------------\n",
      "Epoch : 361 || Loss => 0.7968 || Accuracy => 0.9183\n",
      "----------------------\n",
      "Epoch : 362 || Loss => 0.7968 || Accuracy => 0.9183\n",
      "----------------------\n",
      "Epoch : 363 || Loss => 0.7968 || Accuracy => 0.9182\n",
      "----------------------\n",
      "Epoch : 364 || Loss => 0.7968 || Accuracy => 0.9182\n",
      "----------------------\n",
      "Epoch : 365 || Loss => 0.7968 || Accuracy => 0.9182\n",
      "----------------------\n",
      "Epoch : 366 || Loss => 0.7967 || Accuracy => 0.9182\n",
      "----------------------\n",
      "Epoch : 367 || Loss => 0.7967 || Accuracy => 0.9182\n",
      "----------------------\n",
      "Epoch : 368 || Loss => 0.7967 || Accuracy => 0.9182\n",
      "----------------------\n",
      "Epoch : 369 || Loss => 0.7967 || Accuracy => 0.9182\n",
      "----------------------\n",
      "Epoch : 370 || Loss => 0.7967 || Accuracy => 0.9182\n",
      "----------------------\n",
      "Epoch : 371 || Loss => 0.7967 || Accuracy => 0.9182\n",
      "----------------------\n",
      "Epoch : 372 || Loss => 0.7967 || Accuracy => 0.9182\n",
      "----------------------\n",
      "Epoch : 373 || Loss => 0.7967 || Accuracy => 0.9182\n",
      "----------------------\n",
      "Epoch : 374 || Loss => 0.7967 || Accuracy => 0.9182\n",
      "----------------------\n",
      "Epoch : 375 || Loss => 0.7967 || Accuracy => 0.9182\n",
      "----------------------\n",
      "Epoch : 376 || Loss => 0.7967 || Accuracy => 0.9182\n",
      "----------------------\n",
      "Epoch : 377 || Loss => 0.7967 || Accuracy => 0.9182\n",
      "----------------------\n",
      "Epoch : 378 || Loss => 0.7967 || Accuracy => 0.9182\n",
      "----------------------\n",
      "Epoch : 379 || Loss => 0.7967 || Accuracy => 0.9182\n",
      "----------------------\n",
      "Epoch : 380 || Loss => 0.7967 || Accuracy => 0.9182\n",
      "----------------------\n",
      "Epoch : 381 || Loss => 0.7967 || Accuracy => 0.9182\n",
      "----------------------\n",
      "Epoch : 382 || Loss => 0.7967 || Accuracy => 0.9182\n",
      "----------------------\n",
      "Epoch : 383 || Loss => 0.7967 || Accuracy => 0.9182\n",
      "----------------------\n",
      "Epoch : 384 || Loss => 0.7967 || Accuracy => 0.9182\n",
      "----------------------\n",
      "Epoch : 385 || Loss => 0.7967 || Accuracy => 0.9182\n",
      "----------------------\n",
      "Epoch : 386 || Loss => 0.7966 || Accuracy => 0.9183\n",
      "----------------------\n",
      "Epoch : 387 || Loss => 0.7966 || Accuracy => 0.9183\n",
      "----------------------\n",
      "Epoch : 388 || Loss => 0.7966 || Accuracy => 0.9183\n",
      "----------------------\n",
      "Epoch : 389 || Loss => 0.7966 || Accuracy => 0.9183\n",
      "----------------------\n",
      "Epoch : 390 || Loss => 0.7966 || Accuracy => 0.9183\n",
      "----------------------\n",
      "Epoch : 391 || Loss => 0.7966 || Accuracy => 0.9183\n",
      "----------------------\n",
      "Epoch : 392 || Loss => 0.7966 || Accuracy => 0.9183\n",
      "----------------------\n",
      "Epoch : 393 || Loss => 0.7966 || Accuracy => 0.9183\n",
      "----------------------\n",
      "Epoch : 394 || Loss => 0.7966 || Accuracy => 0.9183\n",
      "----------------------\n",
      "Epoch : 395 || Loss => 0.7966 || Accuracy => 0.9183\n",
      "----------------------\n",
      "Epoch : 396 || Loss => 0.7966 || Accuracy => 0.9183\n",
      "----------------------\n",
      "Epoch : 397 || Loss => 0.7966 || Accuracy => 0.9183\n",
      "----------------------\n",
      "Epoch : 398 || Loss => 0.7966 || Accuracy => 0.9183\n",
      "----------------------\n",
      "Epoch : 399 || Loss => 0.7966 || Accuracy => 0.9183\n",
      "----------------------\n",
      "Epoch : 400 || Loss => 0.7966 || Accuracy => 0.9183\n",
      "----------------------\n",
      "Epoch : 401 || Loss => 0.7966 || Accuracy => 0.9183\n",
      "----------------------\n",
      "Epoch : 402 || Loss => 0.7966 || Accuracy => 0.9183\n",
      "----------------------\n",
      "Epoch : 403 || Loss => 0.7966 || Accuracy => 0.9183\n",
      "----------------------\n",
      "Epoch : 404 || Loss => 0.7966 || Accuracy => 0.9183\n",
      "----------------------\n",
      "Epoch : 405 || Loss => 0.7966 || Accuracy => 0.9183\n",
      "----------------------\n",
      "Epoch : 406 || Loss => 0.7966 || Accuracy => 0.9183\n",
      "----------------------\n",
      "Epoch : 407 || Loss => 0.7965 || Accuracy => 0.9183\n",
      "----------------------\n",
      "Epoch : 408 || Loss => 0.7965 || Accuracy => 0.9183\n",
      "----------------------\n",
      "Epoch : 409 || Loss => 0.7965 || Accuracy => 0.9183\n",
      "----------------------\n",
      "Epoch : 410 || Loss => 0.7965 || Accuracy => 0.9183\n",
      "----------------------\n",
      "Epoch : 411 || Loss => 0.7965 || Accuracy => 0.9183\n",
      "----------------------\n",
      "Epoch : 412 || Loss => 0.7965 || Accuracy => 0.9183\n",
      "----------------------\n",
      "Epoch : 413 || Loss => 0.7965 || Accuracy => 0.9183\n",
      "----------------------\n",
      "Epoch : 414 || Loss => 0.7965 || Accuracy => 0.9183\n",
      "----------------------\n",
      "Epoch : 415 || Loss => 0.7965 || Accuracy => 0.9183\n",
      "----------------------\n",
      "Epoch : 416 || Loss => 0.7965 || Accuracy => 0.9183\n",
      "----------------------\n",
      "Epoch : 417 || Loss => 0.7965 || Accuracy => 0.9183\n",
      "----------------------\n",
      "Epoch : 418 || Loss => 0.7965 || Accuracy => 0.9183\n",
      "----------------------\n",
      "Epoch : 419 || Loss => 0.7965 || Accuracy => 0.9183\n",
      "----------------------\n",
      "Epoch : 420 || Loss => 0.7965 || Accuracy => 0.9183\n",
      "----------------------\n",
      "Epoch : 421 || Loss => 0.7965 || Accuracy => 0.9184\n",
      "----------------------\n",
      "Epoch : 422 || Loss => 0.7965 || Accuracy => 0.9184\n",
      "----------------------\n",
      "Epoch : 423 || Loss => 0.7965 || Accuracy => 0.9184\n",
      "----------------------\n",
      "Epoch : 424 || Loss => 0.7965 || Accuracy => 0.9184\n",
      "----------------------\n",
      "Epoch : 425 || Loss => 0.7965 || Accuracy => 0.9184\n",
      "----------------------\n",
      "Epoch : 426 || Loss => 0.7965 || Accuracy => 0.9184\n",
      "----------------------\n",
      "Epoch : 427 || Loss => 0.7965 || Accuracy => 0.9184\n",
      "----------------------\n",
      "Epoch : 428 || Loss => 0.7965 || Accuracy => 0.9184\n",
      "----------------------\n",
      "Epoch : 429 || Loss => 0.7965 || Accuracy => 0.9184\n",
      "----------------------\n",
      "Epoch : 430 || Loss => 0.7965 || Accuracy => 0.9184\n",
      "----------------------\n",
      "Epoch : 431 || Loss => 0.7964 || Accuracy => 0.9184\n",
      "----------------------\n",
      "Epoch : 432 || Loss => 0.7964 || Accuracy => 0.9184\n",
      "----------------------\n",
      "Epoch : 433 || Loss => 0.7964 || Accuracy => 0.9184\n",
      "----------------------\n",
      "Epoch : 434 || Loss => 0.7964 || Accuracy => 0.9184\n",
      "----------------------\n",
      "Epoch : 435 || Loss => 0.7964 || Accuracy => 0.9184\n",
      "----------------------\n",
      "Epoch : 436 || Loss => 0.7964 || Accuracy => 0.9184\n",
      "----------------------\n",
      "Epoch : 437 || Loss => 0.7964 || Accuracy => 0.9184\n",
      "----------------------\n",
      "Epoch : 438 || Loss => 0.7964 || Accuracy => 0.9184\n",
      "----------------------\n",
      "Epoch : 439 || Loss => 0.7964 || Accuracy => 0.9184\n",
      "----------------------\n",
      "Epoch : 440 || Loss => 0.7964 || Accuracy => 0.9184\n",
      "----------------------\n",
      "Epoch : 441 || Loss => 0.7964 || Accuracy => 0.9184\n",
      "----------------------\n",
      "Epoch : 442 || Loss => 0.7964 || Accuracy => 0.9184\n",
      "----------------------\n",
      "Epoch : 443 || Loss => 0.7964 || Accuracy => 0.9184\n",
      "----------------------\n",
      "Epoch : 444 || Loss => 0.7964 || Accuracy => 0.9184\n",
      "----------------------\n",
      "Epoch : 445 || Loss => 0.7964 || Accuracy => 0.9184\n",
      "----------------------\n",
      "Epoch : 446 || Loss => 0.7964 || Accuracy => 0.9184\n",
      "----------------------\n",
      "Epoch : 447 || Loss => 0.7964 || Accuracy => 0.9185\n",
      "----------------------\n",
      "Epoch : 448 || Loss => 0.7964 || Accuracy => 0.9185\n",
      "----------------------\n",
      "Epoch : 449 || Loss => 0.7964 || Accuracy => 0.9185\n",
      "----------------------\n",
      "Epoch : 450 || Loss => 0.7964 || Accuracy => 0.9185\n",
      "----------------------\n",
      "Epoch : 451 || Loss => 0.7964 || Accuracy => 0.9185\n",
      "----------------------\n",
      "Epoch : 452 || Loss => 0.7964 || Accuracy => 0.9185\n",
      "----------------------\n",
      "Epoch : 453 || Loss => 0.7964 || Accuracy => 0.9185\n",
      "----------------------\n",
      "Epoch : 454 || Loss => 0.7964 || Accuracy => 0.9185\n",
      "----------------------\n",
      "Epoch : 455 || Loss => 0.7964 || Accuracy => 0.9185\n",
      "----------------------\n",
      "Epoch : 456 || Loss => 0.7963 || Accuracy => 0.9185\n",
      "----------------------\n",
      "Epoch : 457 || Loss => 0.7963 || Accuracy => 0.9185\n",
      "----------------------\n",
      "Epoch : 458 || Loss => 0.7963 || Accuracy => 0.9185\n",
      "----------------------\n",
      "Epoch : 459 || Loss => 0.7963 || Accuracy => 0.9185\n",
      "----------------------\n",
      "Epoch : 460 || Loss => 0.7963 || Accuracy => 0.9185\n",
      "----------------------\n",
      "Epoch : 461 || Loss => 0.7963 || Accuracy => 0.9185\n",
      "----------------------\n",
      "Epoch : 462 || Loss => 0.7963 || Accuracy => 0.9185\n",
      "----------------------\n",
      "Epoch : 463 || Loss => 0.7963 || Accuracy => 0.9185\n",
      "----------------------\n",
      "Epoch : 464 || Loss => 0.7963 || Accuracy => 0.9185\n",
      "----------------------\n",
      "Epoch : 465 || Loss => 0.7963 || Accuracy => 0.9185\n",
      "----------------------\n",
      "Epoch : 466 || Loss => 0.7963 || Accuracy => 0.9185\n",
      "----------------------\n",
      "Epoch : 467 || Loss => 0.7963 || Accuracy => 0.9185\n",
      "----------------------\n",
      "Epoch : 468 || Loss => 0.7963 || Accuracy => 0.9185\n",
      "----------------------\n",
      "Epoch : 469 || Loss => 0.7963 || Accuracy => 0.9185\n",
      "----------------------\n",
      "Epoch : 470 || Loss => 0.7963 || Accuracy => 0.9185\n",
      "----------------------\n",
      "Epoch : 471 || Loss => 0.7963 || Accuracy => 0.9185\n",
      "----------------------\n",
      "Epoch : 472 || Loss => 0.7963 || Accuracy => 0.9186\n",
      "----------------------\n",
      "Epoch : 473 || Loss => 0.7963 || Accuracy => 0.9186\n",
      "----------------------\n",
      "Epoch : 474 || Loss => 0.7963 || Accuracy => 0.9186\n",
      "----------------------\n",
      "Epoch : 475 || Loss => 0.7963 || Accuracy => 0.9186\n",
      "----------------------\n",
      "Epoch : 476 || Loss => 0.7963 || Accuracy => 0.9186\n",
      "----------------------\n",
      "Epoch : 477 || Loss => 0.7963 || Accuracy => 0.9186\n",
      "----------------------\n",
      "Epoch : 478 || Loss => 0.7963 || Accuracy => 0.9186\n",
      "----------------------\n",
      "Epoch : 479 || Loss => 0.7963 || Accuracy => 0.9186\n",
      "----------------------\n",
      "Epoch : 480 || Loss => 0.7963 || Accuracy => 0.9186\n",
      "----------------------\n",
      "Epoch : 481 || Loss => 0.7963 || Accuracy => 0.9186\n",
      "----------------------\n",
      "Epoch : 482 || Loss => 0.7963 || Accuracy => 0.9186\n",
      "----------------------\n",
      "Epoch : 483 || Loss => 0.7962 || Accuracy => 0.9186\n",
      "----------------------\n",
      "Epoch : 484 || Loss => 0.7962 || Accuracy => 0.9186\n",
      "----------------------\n",
      "Epoch : 485 || Loss => 0.7962 || Accuracy => 0.9187\n",
      "----------------------\n",
      "Epoch : 486 || Loss => 0.7962 || Accuracy => 0.9187\n",
      "----------------------\n",
      "Epoch : 487 || Loss => 0.7962 || Accuracy => 0.9187\n",
      "----------------------\n",
      "Epoch : 488 || Loss => 0.7962 || Accuracy => 0.9186\n",
      "----------------------\n",
      "Epoch : 489 || Loss => 0.7962 || Accuracy => 0.9186\n",
      "----------------------\n",
      "Epoch : 490 || Loss => 0.7962 || Accuracy => 0.9186\n",
      "----------------------\n",
      "Epoch : 491 || Loss => 0.7962 || Accuracy => 0.9186\n",
      "----------------------\n",
      "Epoch : 492 || Loss => 0.7962 || Accuracy => 0.9186\n",
      "----------------------\n",
      "Epoch : 493 || Loss => 0.7962 || Accuracy => 0.9186\n",
      "----------------------\n",
      "Epoch : 494 || Loss => 0.7962 || Accuracy => 0.9187\n",
      "----------------------\n",
      "Epoch : 495 || Loss => 0.7962 || Accuracy => 0.9187\n",
      "----------------------\n",
      "Epoch : 496 || Loss => 0.7962 || Accuracy => 0.9187\n",
      "----------------------\n",
      "Epoch : 497 || Loss => 0.7962 || Accuracy => 0.9187\n",
      "----------------------\n",
      "Epoch : 498 || Loss => 0.7962 || Accuracy => 0.9187\n",
      "----------------------\n",
      "Epoch : 499 || Loss => 0.7962 || Accuracy => 0.9187\n",
      "----------------------\n",
      "Epoch : 500 || Loss => 0.7962 || Accuracy => 0.9187\n",
      "----------------------\n",
      "Epoch : 501 || Loss => 0.7962 || Accuracy => 0.9187\n",
      "----------------------\n",
      "Epoch : 502 || Loss => 0.7962 || Accuracy => 0.9187\n",
      "----------------------\n",
      "Epoch : 503 || Loss => 0.7962 || Accuracy => 0.9187\n",
      "----------------------\n",
      "Epoch : 504 || Loss => 0.7962 || Accuracy => 0.9187\n",
      "----------------------\n",
      "Epoch : 505 || Loss => 0.7962 || Accuracy => 0.9187\n",
      "----------------------\n",
      "Epoch : 506 || Loss => 0.7962 || Accuracy => 0.9187\n",
      "----------------------\n",
      "Epoch : 507 || Loss => 0.7962 || Accuracy => 0.9187\n",
      "----------------------\n",
      "Epoch : 508 || Loss => 0.7962 || Accuracy => 0.9187\n",
      "----------------------\n",
      "Epoch : 509 || Loss => 0.7962 || Accuracy => 0.9187\n",
      "----------------------\n",
      "Epoch : 510 || Loss => 0.7962 || Accuracy => 0.9187\n",
      "----------------------\n",
      "Epoch : 511 || Loss => 0.7962 || Accuracy => 0.9187\n",
      "----------------------\n",
      "Epoch : 512 || Loss => 0.7962 || Accuracy => 0.9187\n",
      "----------------------\n",
      "Epoch : 513 || Loss => 0.7961 || Accuracy => 0.9187\n",
      "----------------------\n",
      "Epoch : 514 || Loss => 0.7961 || Accuracy => 0.9187\n",
      "----------------------\n",
      "Epoch : 515 || Loss => 0.7961 || Accuracy => 0.9187\n",
      "----------------------\n",
      "Epoch : 516 || Loss => 0.7961 || Accuracy => 0.9187\n",
      "----------------------\n",
      "Epoch : 517 || Loss => 0.7961 || Accuracy => 0.9187\n",
      "----------------------\n",
      "Epoch : 518 || Loss => 0.7961 || Accuracy => 0.9187\n",
      "----------------------\n",
      "Epoch : 519 || Loss => 0.7961 || Accuracy => 0.9188\n",
      "----------------------\n",
      "Epoch : 520 || Loss => 0.7961 || Accuracy => 0.9188\n",
      "----------------------\n",
      "Epoch : 521 || Loss => 0.7961 || Accuracy => 0.9188\n",
      "----------------------\n",
      "Epoch : 522 || Loss => 0.7961 || Accuracy => 0.9188\n",
      "----------------------\n",
      "Epoch : 523 || Loss => 0.7961 || Accuracy => 0.9188\n",
      "----------------------\n",
      "Epoch : 524 || Loss => 0.7961 || Accuracy => 0.9188\n",
      "----------------------\n",
      "Epoch : 525 || Loss => 0.7961 || Accuracy => 0.9188\n",
      "----------------------\n",
      "Epoch : 526 || Loss => 0.7961 || Accuracy => 0.9188\n",
      "----------------------\n",
      "Epoch : 527 || Loss => 0.7961 || Accuracy => 0.9188\n",
      "----------------------\n",
      "Epoch : 528 || Loss => 0.7961 || Accuracy => 0.9188\n",
      "----------------------\n",
      "Epoch : 529 || Loss => 0.7961 || Accuracy => 0.9188\n",
      "----------------------\n",
      "Epoch : 530 || Loss => 0.7961 || Accuracy => 0.9188\n",
      "----------------------\n",
      "Epoch : 531 || Loss => 0.7961 || Accuracy => 0.9187\n",
      "----------------------\n",
      "Epoch : 532 || Loss => 0.7961 || Accuracy => 0.9187\n",
      "----------------------\n",
      "Epoch : 533 || Loss => 0.7961 || Accuracy => 0.9188\n",
      "----------------------\n",
      "Epoch : 534 || Loss => 0.7961 || Accuracy => 0.9188\n",
      "----------------------\n",
      "Epoch : 535 || Loss => 0.7961 || Accuracy => 0.9188\n",
      "----------------------\n",
      "Epoch : 536 || Loss => 0.7961 || Accuracy => 0.9188\n",
      "----------------------\n",
      "Epoch : 537 || Loss => 0.7961 || Accuracy => 0.9188\n",
      "----------------------\n",
      "Epoch : 538 || Loss => 0.7961 || Accuracy => 0.9188\n",
      "----------------------\n",
      "Epoch : 539 || Loss => 0.7961 || Accuracy => 0.9188\n",
      "----------------------\n",
      "Epoch : 540 || Loss => 0.7961 || Accuracy => 0.9188\n",
      "----------------------\n",
      "Epoch : 541 || Loss => 0.7961 || Accuracy => 0.9188\n",
      "----------------------\n",
      "Epoch : 542 || Loss => 0.7961 || Accuracy => 0.9188\n",
      "----------------------\n",
      "Epoch : 543 || Loss => 0.7961 || Accuracy => 0.9188\n",
      "----------------------\n",
      "Epoch : 544 || Loss => 0.7961 || Accuracy => 0.9188\n",
      "----------------------\n",
      "Epoch : 545 || Loss => 0.7961 || Accuracy => 0.9188\n",
      "----------------------\n",
      "Epoch : 546 || Loss => 0.7960 || Accuracy => 0.9187\n",
      "----------------------\n",
      "Epoch : 547 || Loss => 0.7960 || Accuracy => 0.9188\n",
      "----------------------\n",
      "Epoch : 548 || Loss => 0.7960 || Accuracy => 0.9188\n",
      "----------------------\n",
      "Epoch : 549 || Loss => 0.7960 || Accuracy => 0.9188\n",
      "----------------------\n",
      "Epoch : 550 || Loss => 0.7960 || Accuracy => 0.9188\n",
      "----------------------\n",
      "Epoch : 551 || Loss => 0.7960 || Accuracy => 0.9188\n",
      "----------------------\n",
      "Epoch : 552 || Loss => 0.7960 || Accuracy => 0.9188\n",
      "----------------------\n",
      "Epoch : 553 || Loss => 0.7960 || Accuracy => 0.9188\n",
      "----------------------\n",
      "Epoch : 554 || Loss => 0.7960 || Accuracy => 0.9188\n",
      "----------------------\n",
      "Epoch : 555 || Loss => 0.7960 || Accuracy => 0.9188\n",
      "----------------------\n",
      "Epoch : 556 || Loss => 0.7960 || Accuracy => 0.9187\n",
      "----------------------\n",
      "Epoch : 557 || Loss => 0.7960 || Accuracy => 0.9187\n",
      "----------------------\n",
      "Epoch : 558 || Loss => 0.7960 || Accuracy => 0.9187\n",
      "----------------------\n",
      "Epoch : 559 || Loss => 0.7960 || Accuracy => 0.9187\n",
      "----------------------\n",
      "Epoch : 560 || Loss => 0.7960 || Accuracy => 0.9187\n",
      "----------------------\n",
      "Epoch : 561 || Loss => 0.7960 || Accuracy => 0.9188\n",
      "----------------------\n",
      "Epoch : 562 || Loss => 0.7960 || Accuracy => 0.9188\n",
      "----------------------\n",
      "Epoch : 563 || Loss => 0.7960 || Accuracy => 0.9188\n",
      "----------------------\n",
      "Epoch : 564 || Loss => 0.7960 || Accuracy => 0.9188\n",
      "----------------------\n",
      "Epoch : 565 || Loss => 0.7960 || Accuracy => 0.9187\n",
      "----------------------\n",
      "Epoch : 566 || Loss => 0.7960 || Accuracy => 0.9187\n",
      "----------------------\n",
      "Epoch : 567 || Loss => 0.7960 || Accuracy => 0.9188\n",
      "----------------------\n",
      "Epoch : 568 || Loss => 0.7960 || Accuracy => 0.9188\n",
      "----------------------\n",
      "Epoch : 569 || Loss => 0.7960 || Accuracy => 0.9188\n",
      "----------------------\n",
      "Epoch : 570 || Loss => 0.7960 || Accuracy => 0.9188\n",
      "----------------------\n",
      "Epoch : 571 || Loss => 0.7960 || Accuracy => 0.9188\n",
      "----------------------\n",
      "Epoch : 572 || Loss => 0.7960 || Accuracy => 0.9188\n",
      "----------------------\n",
      "Epoch : 573 || Loss => 0.7960 || Accuracy => 0.9188\n",
      "----------------------\n",
      "Epoch : 574 || Loss => 0.7960 || Accuracy => 0.9188\n",
      "----------------------\n",
      "Epoch : 575 || Loss => 0.7960 || Accuracy => 0.9188\n",
      "----------------------\n",
      "Epoch : 576 || Loss => 0.7960 || Accuracy => 0.9188\n",
      "----------------------\n",
      "Epoch : 577 || Loss => 0.7960 || Accuracy => 0.9188\n",
      "----------------------\n",
      "Epoch : 578 || Loss => 0.7960 || Accuracy => 0.9188\n",
      "----------------------\n",
      "Epoch : 579 || Loss => 0.7960 || Accuracy => 0.9188\n",
      "----------------------\n",
      "Epoch : 580 || Loss => 0.7960 || Accuracy => 0.9188\n",
      "----------------------\n",
      "Epoch : 581 || Loss => 0.7960 || Accuracy => 0.9188\n",
      "----------------------\n",
      "Epoch : 582 || Loss => 0.7959 || Accuracy => 0.9188\n",
      "----------------------\n",
      "Epoch : 583 || Loss => 0.7959 || Accuracy => 0.9188\n",
      "----------------------\n",
      "Epoch : 584 || Loss => 0.7959 || Accuracy => 0.9188\n",
      "----------------------\n",
      "Epoch : 585 || Loss => 0.7959 || Accuracy => 0.9188\n",
      "----------------------\n",
      "Epoch : 586 || Loss => 0.7959 || Accuracy => 0.9188\n",
      "----------------------\n",
      "Epoch : 587 || Loss => 0.7959 || Accuracy => 0.9188\n",
      "----------------------\n",
      "Epoch : 588 || Loss => 0.7959 || Accuracy => 0.9188\n",
      "----------------------\n",
      "Epoch : 589 || Loss => 0.7959 || Accuracy => 0.9188\n",
      "----------------------\n",
      "Epoch : 590 || Loss => 0.7959 || Accuracy => 0.9188\n",
      "----------------------\n",
      "Epoch : 591 || Loss => 0.7959 || Accuracy => 0.9188\n",
      "----------------------\n",
      "Epoch : 592 || Loss => 0.7959 || Accuracy => 0.9188\n",
      "----------------------\n",
      "Epoch : 593 || Loss => 0.7959 || Accuracy => 0.9188\n",
      "----------------------\n",
      "Epoch : 594 || Loss => 0.7959 || Accuracy => 0.9188\n",
      "----------------------\n",
      "Epoch : 595 || Loss => 0.7959 || Accuracy => 0.9188\n",
      "----------------------\n",
      "Epoch : 596 || Loss => 0.7959 || Accuracy => 0.9188\n",
      "----------------------\n",
      "Epoch : 597 || Loss => 0.7959 || Accuracy => 0.9188\n",
      "----------------------\n",
      "Epoch : 598 || Loss => 0.7959 || Accuracy => 0.9188\n",
      "----------------------\n",
      "Epoch : 599 || Loss => 0.7959 || Accuracy => 0.9188\n",
      "----------------------\n",
      "Epoch : 600 || Loss => 0.7959 || Accuracy => 0.9188\n",
      "----------------------\n",
      "Epoch : 601 || Loss => 0.7959 || Accuracy => 0.9188\n",
      "----------------------\n",
      "Epoch : 602 || Loss => 0.7959 || Accuracy => 0.9188\n",
      "----------------------\n",
      "Epoch : 603 || Loss => 0.7959 || Accuracy => 0.9188\n",
      "----------------------\n",
      "Epoch : 604 || Loss => 0.7959 || Accuracy => 0.9188\n",
      "----------------------\n",
      "Epoch : 605 || Loss => 0.7959 || Accuracy => 0.9188\n",
      "----------------------\n",
      "Epoch : 606 || Loss => 0.7959 || Accuracy => 0.9188\n",
      "----------------------\n",
      "Epoch : 607 || Loss => 0.7959 || Accuracy => 0.9188\n",
      "----------------------\n",
      "Epoch : 608 || Loss => 0.7959 || Accuracy => 0.9189\n",
      "----------------------\n",
      "Epoch : 609 || Loss => 0.7959 || Accuracy => 0.9189\n",
      "----------------------\n",
      "Epoch : 610 || Loss => 0.7959 || Accuracy => 0.9189\n",
      "----------------------\n",
      "Epoch : 611 || Loss => 0.7959 || Accuracy => 0.9189\n",
      "----------------------\n",
      "Epoch : 612 || Loss => 0.7959 || Accuracy => 0.9189\n",
      "----------------------\n",
      "Epoch : 613 || Loss => 0.7959 || Accuracy => 0.9189\n",
      "----------------------\n",
      "Epoch : 614 || Loss => 0.7959 || Accuracy => 0.9189\n",
      "----------------------\n",
      "Epoch : 615 || Loss => 0.7959 || Accuracy => 0.9189\n",
      "----------------------\n",
      "Epoch : 616 || Loss => 0.7959 || Accuracy => 0.9189\n",
      "----------------------\n",
      "Epoch : 617 || Loss => 0.7959 || Accuracy => 0.9189\n",
      "----------------------\n",
      "Epoch : 618 || Loss => 0.7959 || Accuracy => 0.9189\n",
      "----------------------\n",
      "Epoch : 619 || Loss => 0.7959 || Accuracy => 0.9189\n",
      "----------------------\n",
      "Epoch : 620 || Loss => 0.7959 || Accuracy => 0.9189\n",
      "----------------------\n",
      "Epoch : 621 || Loss => 0.7958 || Accuracy => 0.9189\n",
      "----------------------\n",
      "Epoch : 622 || Loss => 0.7958 || Accuracy => 0.9189\n",
      "----------------------\n",
      "Epoch : 623 || Loss => 0.7958 || Accuracy => 0.9189\n",
      "----------------------\n",
      "Epoch : 624 || Loss => 0.7958 || Accuracy => 0.9189\n",
      "----------------------\n",
      "Epoch : 625 || Loss => 0.7958 || Accuracy => 0.9189\n",
      "----------------------\n",
      "Epoch : 626 || Loss => 0.7958 || Accuracy => 0.9189\n",
      "----------------------\n",
      "Epoch : 627 || Loss => 0.7958 || Accuracy => 0.9189\n",
      "----------------------\n",
      "Epoch : 628 || Loss => 0.7958 || Accuracy => 0.9189\n",
      "----------------------\n",
      "Epoch : 629 || Loss => 0.7958 || Accuracy => 0.9189\n",
      "----------------------\n",
      "Epoch : 630 || Loss => 0.7958 || Accuracy => 0.9189\n",
      "----------------------\n",
      "Epoch : 631 || Loss => 0.7958 || Accuracy => 0.9189\n",
      "----------------------\n",
      "Epoch : 632 || Loss => 0.7958 || Accuracy => 0.9189\n",
      "----------------------\n",
      "Epoch : 633 || Loss => 0.7958 || Accuracy => 0.9189\n",
      "----------------------\n",
      "Epoch : 634 || Loss => 0.7958 || Accuracy => 0.9189\n",
      "----------------------\n",
      "Epoch : 635 || Loss => 0.7958 || Accuracy => 0.9189\n",
      "----------------------\n",
      "Epoch : 636 || Loss => 0.7958 || Accuracy => 0.9189\n",
      "----------------------\n",
      "Epoch : 637 || Loss => 0.7958 || Accuracy => 0.9190\n",
      "----------------------\n",
      "Epoch : 638 || Loss => 0.7958 || Accuracy => 0.9190\n",
      "----------------------\n",
      "Epoch : 639 || Loss => 0.7958 || Accuracy => 0.9190\n",
      "----------------------\n",
      "Epoch : 640 || Loss => 0.7958 || Accuracy => 0.9190\n",
      "----------------------\n",
      "Epoch : 641 || Loss => 0.7958 || Accuracy => 0.9190\n",
      "----------------------\n",
      "Epoch : 642 || Loss => 0.7958 || Accuracy => 0.9190\n",
      "----------------------\n",
      "Epoch : 643 || Loss => 0.7958 || Accuracy => 0.9190\n",
      "----------------------\n",
      "Epoch : 644 || Loss => 0.7958 || Accuracy => 0.9190\n",
      "----------------------\n",
      "Epoch : 645 || Loss => 0.7958 || Accuracy => 0.9190\n",
      "----------------------\n",
      "Epoch : 646 || Loss => 0.7958 || Accuracy => 0.9190\n",
      "----------------------\n",
      "Epoch : 647 || Loss => 0.7958 || Accuracy => 0.9190\n",
      "----------------------\n",
      "Epoch : 648 || Loss => 0.7958 || Accuracy => 0.9190\n",
      "----------------------\n",
      "Epoch : 649 || Loss => 0.7958 || Accuracy => 0.9190\n",
      "----------------------\n",
      "Epoch : 650 || Loss => 0.7958 || Accuracy => 0.9190\n",
      "----------------------\n",
      "Epoch : 651 || Loss => 0.7958 || Accuracy => 0.9190\n",
      "----------------------\n",
      "Epoch : 652 || Loss => 0.7958 || Accuracy => 0.9190\n",
      "----------------------\n",
      "Epoch : 653 || Loss => 0.7958 || Accuracy => 0.9190\n",
      "----------------------\n",
      "Epoch : 654 || Loss => 0.7958 || Accuracy => 0.9190\n",
      "----------------------\n",
      "Epoch : 655 || Loss => 0.7958 || Accuracy => 0.9190\n",
      "----------------------\n",
      "Epoch : 656 || Loss => 0.7958 || Accuracy => 0.9190\n",
      "----------------------\n",
      "Epoch : 657 || Loss => 0.7958 || Accuracy => 0.9190\n",
      "----------------------\n",
      "Epoch : 658 || Loss => 0.7958 || Accuracy => 0.9190\n",
      "----------------------\n",
      "Epoch : 659 || Loss => 0.7958 || Accuracy => 0.9190\n",
      "----------------------\n",
      "Epoch : 660 || Loss => 0.7958 || Accuracy => 0.9190\n",
      "----------------------\n",
      "Epoch : 661 || Loss => 0.7958 || Accuracy => 0.9190\n",
      "----------------------\n",
      "Epoch : 662 || Loss => 0.7958 || Accuracy => 0.9190\n",
      "----------------------\n",
      "Epoch : 663 || Loss => 0.7958 || Accuracy => 0.9190\n",
      "----------------------\n",
      "Epoch : 664 || Loss => 0.7958 || Accuracy => 0.9190\n",
      "----------------------\n",
      "Epoch : 665 || Loss => 0.7957 || Accuracy => 0.9190\n",
      "----------------------\n",
      "Epoch : 666 || Loss => 0.7957 || Accuracy => 0.9190\n",
      "----------------------\n",
      "Epoch : 667 || Loss => 0.7957 || Accuracy => 0.9190\n",
      "----------------------\n",
      "Epoch : 668 || Loss => 0.7957 || Accuracy => 0.9190\n",
      "----------------------\n",
      "Epoch : 669 || Loss => 0.7957 || Accuracy => 0.9190\n",
      "----------------------\n",
      "Epoch : 670 || Loss => 0.7957 || Accuracy => 0.9190\n",
      "----------------------\n",
      "Epoch : 671 || Loss => 0.7957 || Accuracy => 0.9190\n",
      "----------------------\n",
      "Epoch : 672 || Loss => 0.7957 || Accuracy => 0.9190\n",
      "----------------------\n",
      "Epoch : 673 || Loss => 0.7957 || Accuracy => 0.9190\n",
      "----------------------\n",
      "Epoch : 674 || Loss => 0.7957 || Accuracy => 0.9190\n",
      "----------------------\n",
      "Epoch : 675 || Loss => 0.7957 || Accuracy => 0.9190\n",
      "----------------------\n",
      "Epoch : 676 || Loss => 0.7957 || Accuracy => 0.9190\n",
      "----------------------\n",
      "Epoch : 677 || Loss => 0.7957 || Accuracy => 0.9190\n",
      "----------------------\n",
      "Epoch : 678 || Loss => 0.7957 || Accuracy => 0.9190\n",
      "----------------------\n",
      "Epoch : 679 || Loss => 0.7957 || Accuracy => 0.9190\n",
      "----------------------\n",
      "Epoch : 680 || Loss => 0.7957 || Accuracy => 0.9190\n",
      "----------------------\n",
      "Epoch : 681 || Loss => 0.7957 || Accuracy => 0.9190\n",
      "----------------------\n",
      "Epoch : 682 || Loss => 0.7957 || Accuracy => 0.9190\n",
      "----------------------\n",
      "Epoch : 683 || Loss => 0.7957 || Accuracy => 0.9190\n",
      "----------------------\n",
      "Epoch : 684 || Loss => 0.7957 || Accuracy => 0.9190\n",
      "----------------------\n",
      "Epoch : 685 || Loss => 0.7957 || Accuracy => 0.9190\n",
      "----------------------\n",
      "Epoch : 686 || Loss => 0.7957 || Accuracy => 0.9190\n",
      "----------------------\n",
      "Epoch : 687 || Loss => 0.7957 || Accuracy => 0.9190\n",
      "----------------------\n",
      "Epoch : 688 || Loss => 0.7957 || Accuracy => 0.9190\n",
      "----------------------\n",
      "Epoch : 689 || Loss => 0.7957 || Accuracy => 0.9190\n",
      "----------------------\n",
      "Epoch : 690 || Loss => 0.7957 || Accuracy => 0.9190\n",
      "----------------------\n",
      "Epoch : 691 || Loss => 0.7957 || Accuracy => 0.9190\n",
      "----------------------\n",
      "Epoch : 692 || Loss => 0.7957 || Accuracy => 0.9190\n",
      "----------------------\n",
      "Epoch : 693 || Loss => 0.7957 || Accuracy => 0.9190\n",
      "----------------------\n",
      "Epoch : 694 || Loss => 0.7957 || Accuracy => 0.9190\n",
      "----------------------\n",
      "Epoch : 695 || Loss => 0.7957 || Accuracy => 0.9190\n",
      "----------------------\n",
      "Epoch : 696 || Loss => 0.7957 || Accuracy => 0.9190\n",
      "----------------------\n",
      "Epoch : 697 || Loss => 0.7957 || Accuracy => 0.9190\n",
      "----------------------\n",
      "Epoch : 698 || Loss => 0.7957 || Accuracy => 0.9190\n",
      "----------------------\n",
      "Epoch : 699 || Loss => 0.7957 || Accuracy => 0.9190\n",
      "----------------------\n",
      "Epoch : 700 || Loss => 0.7957 || Accuracy => 0.9190\n",
      "----------------------\n",
      "Epoch : 701 || Loss => 0.7957 || Accuracy => 0.9190\n",
      "----------------------\n",
      "Epoch : 702 || Loss => 0.7957 || Accuracy => 0.9190\n",
      "----------------------\n",
      "Epoch : 703 || Loss => 0.7957 || Accuracy => 0.9190\n",
      "----------------------\n",
      "Epoch : 704 || Loss => 0.7957 || Accuracy => 0.9190\n",
      "----------------------\n",
      "Epoch : 705 || Loss => 0.7957 || Accuracy => 0.9190\n",
      "----------------------\n",
      "Epoch : 706 || Loss => 0.7957 || Accuracy => 0.9190\n",
      "----------------------\n",
      "Epoch : 707 || Loss => 0.7957 || Accuracy => 0.9190\n",
      "----------------------\n",
      "Epoch : 708 || Loss => 0.7957 || Accuracy => 0.9190\n",
      "----------------------\n",
      "Epoch : 709 || Loss => 0.7957 || Accuracy => 0.9190\n",
      "----------------------\n",
      "Epoch : 710 || Loss => 0.7957 || Accuracy => 0.9190\n",
      "----------------------\n",
      "Epoch : 711 || Loss => 0.7957 || Accuracy => 0.9190\n",
      "----------------------\n",
      "Epoch : 712 || Loss => 0.7957 || Accuracy => 0.9190\n",
      "----------------------\n",
      "Epoch : 713 || Loss => 0.7956 || Accuracy => 0.9190\n",
      "----------------------\n",
      "Epoch : 714 || Loss => 0.7956 || Accuracy => 0.9190\n",
      "----------------------\n",
      "Epoch : 715 || Loss => 0.7956 || Accuracy => 0.9190\n",
      "----------------------\n",
      "Epoch : 716 || Loss => 0.7956 || Accuracy => 0.9190\n",
      "----------------------\n",
      "Epoch : 717 || Loss => 0.7956 || Accuracy => 0.9190\n",
      "----------------------\n",
      "Epoch : 718 || Loss => 0.7956 || Accuracy => 0.9190\n",
      "----------------------\n",
      "Epoch : 719 || Loss => 0.7956 || Accuracy => 0.9190\n",
      "----------------------\n",
      "Epoch : 720 || Loss => 0.7956 || Accuracy => 0.9190\n",
      "----------------------\n",
      "Epoch : 721 || Loss => 0.7956 || Accuracy => 0.9190\n",
      "----------------------\n",
      "Epoch : 722 || Loss => 0.7956 || Accuracy => 0.9190\n",
      "----------------------\n",
      "Epoch : 723 || Loss => 0.7956 || Accuracy => 0.9190\n",
      "----------------------\n",
      "Epoch : 724 || Loss => 0.7956 || Accuracy => 0.9190\n",
      "----------------------\n",
      "Epoch : 725 || Loss => 0.7956 || Accuracy => 0.9190\n",
      "----------------------\n",
      "Epoch : 726 || Loss => 0.7956 || Accuracy => 0.9190\n",
      "----------------------\n",
      "Epoch : 727 || Loss => 0.7956 || Accuracy => 0.9190\n",
      "----------------------\n",
      "Epoch : 728 || Loss => 0.7956 || Accuracy => 0.9190\n",
      "----------------------\n",
      "Epoch : 729 || Loss => 0.7956 || Accuracy => 0.9190\n",
      "----------------------\n",
      "Epoch : 730 || Loss => 0.7956 || Accuracy => 0.9190\n",
      "----------------------\n",
      "Epoch : 731 || Loss => 0.7956 || Accuracy => 0.9190\n",
      "----------------------\n",
      "Epoch : 732 || Loss => 0.7956 || Accuracy => 0.9190\n",
      "----------------------\n",
      "Epoch : 733 || Loss => 0.7956 || Accuracy => 0.9190\n",
      "----------------------\n",
      "Epoch : 734 || Loss => 0.7956 || Accuracy => 0.9190\n",
      "----------------------\n",
      "Epoch : 735 || Loss => 0.7956 || Accuracy => 0.9190\n",
      "----------------------\n",
      "Epoch : 736 || Loss => 0.7956 || Accuracy => 0.9190\n",
      "----------------------\n",
      "Epoch : 737 || Loss => 0.7956 || Accuracy => 0.9190\n",
      "----------------------\n",
      "Epoch : 738 || Loss => 0.7956 || Accuracy => 0.9190\n",
      "----------------------\n",
      "Epoch : 739 || Loss => 0.7956 || Accuracy => 0.9190\n",
      "----------------------\n",
      "Epoch : 740 || Loss => 0.7956 || Accuracy => 0.9190\n",
      "----------------------\n",
      "Epoch : 741 || Loss => 0.7956 || Accuracy => 0.9190\n",
      "----------------------\n",
      "Epoch : 742 || Loss => 0.7956 || Accuracy => 0.9190\n",
      "----------------------\n",
      "Epoch : 743 || Loss => 0.7956 || Accuracy => 0.9190\n",
      "----------------------\n",
      "Epoch : 744 || Loss => 0.7956 || Accuracy => 0.9190\n",
      "----------------------\n",
      "Epoch : 745 || Loss => 0.7956 || Accuracy => 0.9190\n",
      "----------------------\n",
      "Epoch : 746 || Loss => 0.7956 || Accuracy => 0.9190\n",
      "----------------------\n",
      "Epoch : 747 || Loss => 0.7956 || Accuracy => 0.9190\n",
      "----------------------\n",
      "Epoch : 748 || Loss => 0.7956 || Accuracy => 0.9190\n",
      "----------------------\n",
      "Epoch : 749 || Loss => 0.7956 || Accuracy => 0.9190\n",
      "----------------------\n",
      "Epoch : 750 || Loss => 0.7956 || Accuracy => 0.9190\n",
      "----------------------\n",
      "Epoch : 751 || Loss => 0.7956 || Accuracy => 0.9190\n",
      "----------------------\n",
      "Epoch : 752 || Loss => 0.7956 || Accuracy => 0.9190\n",
      "----------------------\n",
      "Epoch : 753 || Loss => 0.7956 || Accuracy => 0.9190\n",
      "----------------------\n",
      "Epoch : 754 || Loss => 0.7956 || Accuracy => 0.9190\n",
      "----------------------\n",
      "Epoch : 755 || Loss => 0.7956 || Accuracy => 0.9190\n",
      "----------------------\n",
      "Epoch : 756 || Loss => 0.7956 || Accuracy => 0.9190\n",
      "----------------------\n",
      "Epoch : 757 || Loss => 0.7956 || Accuracy => 0.9190\n",
      "----------------------\n",
      "Epoch : 758 || Loss => 0.7956 || Accuracy => 0.9190\n",
      "----------------------\n",
      "Epoch : 759 || Loss => 0.7956 || Accuracy => 0.9190\n",
      "----------------------\n",
      "Epoch : 760 || Loss => 0.7956 || Accuracy => 0.9190\n",
      "----------------------\n",
      "Epoch : 761 || Loss => 0.7956 || Accuracy => 0.9190\n",
      "----------------------\n",
      "Epoch : 762 || Loss => 0.7956 || Accuracy => 0.9190\n",
      "----------------------\n",
      "Epoch : 763 || Loss => 0.7956 || Accuracy => 0.9190\n",
      "----------------------\n",
      "Epoch : 764 || Loss => 0.7956 || Accuracy => 0.9190\n",
      "----------------------\n",
      "Epoch : 765 || Loss => 0.7956 || Accuracy => 0.9190\n",
      "----------------------\n",
      "Epoch : 766 || Loss => 0.7955 || Accuracy => 0.9190\n",
      "----------------------\n",
      "Epoch : 767 || Loss => 0.7955 || Accuracy => 0.9190\n",
      "----------------------\n",
      "Epoch : 768 || Loss => 0.7955 || Accuracy => 0.9190\n",
      "----------------------\n",
      "Epoch : 769 || Loss => 0.7955 || Accuracy => 0.9190\n",
      "----------------------\n",
      "Epoch : 770 || Loss => 0.7955 || Accuracy => 0.9191\n",
      "----------------------\n",
      "Epoch : 771 || Loss => 0.7955 || Accuracy => 0.9191\n",
      "----------------------\n",
      "Epoch : 772 || Loss => 0.7955 || Accuracy => 0.9191\n",
      "----------------------\n",
      "Epoch : 773 || Loss => 0.7955 || Accuracy => 0.9190\n",
      "----------------------\n",
      "Epoch : 774 || Loss => 0.7955 || Accuracy => 0.9190\n",
      "----------------------\n",
      "Epoch : 775 || Loss => 0.7955 || Accuracy => 0.9190\n",
      "----------------------\n",
      "Epoch : 776 || Loss => 0.7955 || Accuracy => 0.9190\n",
      "----------------------\n",
      "Epoch : 777 || Loss => 0.7955 || Accuracy => 0.9190\n",
      "----------------------\n",
      "Epoch : 778 || Loss => 0.7955 || Accuracy => 0.9190\n",
      "----------------------\n",
      "Epoch : 779 || Loss => 0.7955 || Accuracy => 0.9190\n",
      "----------------------\n",
      "Epoch : 780 || Loss => 0.7955 || Accuracy => 0.9190\n",
      "----------------------\n",
      "Epoch : 781 || Loss => 0.7955 || Accuracy => 0.9190\n",
      "----------------------\n",
      "Epoch : 782 || Loss => 0.7955 || Accuracy => 0.9190\n",
      "----------------------\n",
      "Epoch : 783 || Loss => 0.7955 || Accuracy => 0.9190\n",
      "----------------------\n",
      "Epoch : 784 || Loss => 0.7955 || Accuracy => 0.9190\n",
      "----------------------\n",
      "Epoch : 785 || Loss => 0.7955 || Accuracy => 0.9190\n",
      "----------------------\n",
      "Epoch : 786 || Loss => 0.7955 || Accuracy => 0.9190\n",
      "----------------------\n",
      "Epoch : 787 || Loss => 0.7955 || Accuracy => 0.9190\n",
      "----------------------\n",
      "Epoch : 788 || Loss => 0.7955 || Accuracy => 0.9190\n",
      "----------------------\n",
      "Epoch : 789 || Loss => 0.7955 || Accuracy => 0.9190\n",
      "----------------------\n",
      "Epoch : 790 || Loss => 0.7955 || Accuracy => 0.9190\n",
      "----------------------\n",
      "Epoch : 791 || Loss => 0.7955 || Accuracy => 0.9190\n",
      "----------------------\n",
      "Epoch : 792 || Loss => 0.7955 || Accuracy => 0.9190\n",
      "----------------------\n",
      "Epoch : 793 || Loss => 0.7955 || Accuracy => 0.9190\n",
      "----------------------\n",
      "Epoch : 794 || Loss => 0.7955 || Accuracy => 0.9190\n",
      "----------------------\n",
      "Epoch : 795 || Loss => 0.7955 || Accuracy => 0.9191\n",
      "----------------------\n",
      "Epoch : 796 || Loss => 0.7955 || Accuracy => 0.9191\n",
      "----------------------\n",
      "Epoch : 797 || Loss => 0.7955 || Accuracy => 0.9191\n",
      "----------------------\n",
      "Epoch : 798 || Loss => 0.7955 || Accuracy => 0.9191\n",
      "----------------------\n",
      "Epoch : 799 || Loss => 0.7955 || Accuracy => 0.9191\n",
      "----------------------\n",
      "Epoch : 800 || Loss => 0.7955 || Accuracy => 0.9191\n",
      "----------------------\n",
      "Epoch : 801 || Loss => 0.7955 || Accuracy => 0.9191\n",
      "----------------------\n",
      "Epoch : 802 || Loss => 0.7955 || Accuracy => 0.9191\n",
      "----------------------\n",
      "Epoch : 803 || Loss => 0.7955 || Accuracy => 0.9191\n",
      "----------------------\n",
      "Epoch : 804 || Loss => 0.7955 || Accuracy => 0.9191\n",
      "----------------------\n",
      "Epoch : 805 || Loss => 0.7955 || Accuracy => 0.9191\n",
      "----------------------\n",
      "Epoch : 806 || Loss => 0.7955 || Accuracy => 0.9191\n",
      "----------------------\n",
      "Epoch : 807 || Loss => 0.7955 || Accuracy => 0.9191\n",
      "----------------------\n",
      "Epoch : 808 || Loss => 0.7955 || Accuracy => 0.9191\n",
      "----------------------\n",
      "Epoch : 809 || Loss => 0.7955 || Accuracy => 0.9191\n",
      "----------------------\n",
      "Epoch : 810 || Loss => 0.7955 || Accuracy => 0.9191\n",
      "----------------------\n",
      "Epoch : 811 || Loss => 0.7955 || Accuracy => 0.9191\n",
      "----------------------\n",
      "Epoch : 812 || Loss => 0.7955 || Accuracy => 0.9191\n",
      "----------------------\n",
      "Epoch : 813 || Loss => 0.7955 || Accuracy => 0.9191\n",
      "----------------------\n",
      "Epoch : 814 || Loss => 0.7955 || Accuracy => 0.9191\n",
      "----------------------\n",
      "Epoch : 815 || Loss => 0.7955 || Accuracy => 0.9191\n",
      "----------------------\n",
      "Epoch : 816 || Loss => 0.7955 || Accuracy => 0.9191\n",
      "----------------------\n",
      "Epoch : 817 || Loss => 0.7955 || Accuracy => 0.9191\n",
      "----------------------\n",
      "Epoch : 818 || Loss => 0.7955 || Accuracy => 0.9191\n",
      "----------------------\n",
      "Epoch : 819 || Loss => 0.7955 || Accuracy => 0.9191\n",
      "----------------------\n",
      "Epoch : 820 || Loss => 0.7955 || Accuracy => 0.9191\n",
      "----------------------\n",
      "Epoch : 821 || Loss => 0.7955 || Accuracy => 0.9191\n",
      "----------------------\n",
      "Epoch : 822 || Loss => 0.7955 || Accuracy => 0.9191\n",
      "----------------------\n",
      "Epoch : 823 || Loss => 0.7955 || Accuracy => 0.9191\n",
      "----------------------\n",
      "Epoch : 824 || Loss => 0.7955 || Accuracy => 0.9191\n",
      "----------------------\n",
      "Epoch : 825 || Loss => 0.7955 || Accuracy => 0.9191\n",
      "----------------------\n",
      "Epoch : 826 || Loss => 0.7954 || Accuracy => 0.9191\n",
      "----------------------\n",
      "Epoch : 827 || Loss => 0.7954 || Accuracy => 0.9191\n",
      "----------------------\n",
      "Epoch : 828 || Loss => 0.7954 || Accuracy => 0.9191\n",
      "----------------------\n",
      "Epoch : 829 || Loss => 0.7954 || Accuracy => 0.9191\n",
      "----------------------\n",
      "Epoch : 830 || Loss => 0.7954 || Accuracy => 0.9191\n",
      "----------------------\n",
      "Epoch : 831 || Loss => 0.7954 || Accuracy => 0.9191\n",
      "----------------------\n",
      "Epoch : 832 || Loss => 0.7954 || Accuracy => 0.9191\n",
      "----------------------\n",
      "Epoch : 833 || Loss => 0.7954 || Accuracy => 0.9191\n",
      "----------------------\n",
      "Epoch : 834 || Loss => 0.7954 || Accuracy => 0.9191\n",
      "----------------------\n",
      "Epoch : 835 || Loss => 0.7954 || Accuracy => 0.9191\n",
      "----------------------\n",
      "Epoch : 836 || Loss => 0.7954 || Accuracy => 0.9191\n",
      "----------------------\n",
      "Epoch : 837 || Loss => 0.7954 || Accuracy => 0.9191\n",
      "----------------------\n",
      "Epoch : 838 || Loss => 0.7954 || Accuracy => 0.9191\n",
      "----------------------\n",
      "Epoch : 839 || Loss => 0.7954 || Accuracy => 0.9191\n",
      "----------------------\n",
      "Epoch : 840 || Loss => 0.7954 || Accuracy => 0.9191\n",
      "----------------------\n",
      "Epoch : 841 || Loss => 0.7954 || Accuracy => 0.9191\n",
      "----------------------\n",
      "Epoch : 842 || Loss => 0.7954 || Accuracy => 0.9191\n",
      "----------------------\n",
      "Epoch : 843 || Loss => 0.7954 || Accuracy => 0.9191\n",
      "----------------------\n",
      "Epoch : 844 || Loss => 0.7954 || Accuracy => 0.9191\n",
      "----------------------\n",
      "Epoch : 845 || Loss => 0.7954 || Accuracy => 0.9191\n",
      "----------------------\n",
      "Epoch : 846 || Loss => 0.7954 || Accuracy => 0.9191\n",
      "----------------------\n",
      "Epoch : 847 || Loss => 0.7954 || Accuracy => 0.9191\n",
      "----------------------\n",
      "Epoch : 848 || Loss => 0.7954 || Accuracy => 0.9191\n",
      "----------------------\n",
      "Epoch : 849 || Loss => 0.7954 || Accuracy => 0.9191\n",
      "----------------------\n",
      "Epoch : 850 || Loss => 0.7954 || Accuracy => 0.9192\n",
      "----------------------\n",
      "Epoch : 851 || Loss => 0.7954 || Accuracy => 0.9192\n",
      "----------------------\n",
      "Epoch : 852 || Loss => 0.7954 || Accuracy => 0.9192\n",
      "----------------------\n",
      "Epoch : 853 || Loss => 0.7954 || Accuracy => 0.9192\n",
      "----------------------\n",
      "Epoch : 854 || Loss => 0.7954 || Accuracy => 0.9192\n",
      "----------------------\n",
      "Epoch : 855 || Loss => 0.7954 || Accuracy => 0.9192\n",
      "----------------------\n",
      "Epoch : 856 || Loss => 0.7954 || Accuracy => 0.9191\n",
      "----------------------\n",
      "Epoch : 857 || Loss => 0.7954 || Accuracy => 0.9191\n",
      "----------------------\n",
      "Epoch : 858 || Loss => 0.7954 || Accuracy => 0.9191\n",
      "----------------------\n",
      "Epoch : 859 || Loss => 0.7954 || Accuracy => 0.9191\n",
      "----------------------\n",
      "Epoch : 860 || Loss => 0.7954 || Accuracy => 0.9191\n",
      "----------------------\n",
      "Epoch : 861 || Loss => 0.7954 || Accuracy => 0.9191\n",
      "----------------------\n",
      "Epoch : 862 || Loss => 0.7954 || Accuracy => 0.9191\n",
      "----------------------\n",
      "Epoch : 863 || Loss => 0.7954 || Accuracy => 0.9191\n",
      "----------------------\n",
      "Epoch : 864 || Loss => 0.7954 || Accuracy => 0.9191\n",
      "----------------------\n",
      "Epoch : 865 || Loss => 0.7954 || Accuracy => 0.9191\n",
      "----------------------\n",
      "Epoch : 866 || Loss => 0.7954 || Accuracy => 0.9191\n",
      "----------------------\n",
      "Epoch : 867 || Loss => 0.7954 || Accuracy => 0.9191\n",
      "----------------------\n",
      "Epoch : 868 || Loss => 0.7954 || Accuracy => 0.9191\n",
      "----------------------\n",
      "Epoch : 869 || Loss => 0.7954 || Accuracy => 0.9191\n",
      "----------------------\n",
      "Epoch : 870 || Loss => 0.7954 || Accuracy => 0.9191\n",
      "----------------------\n",
      "Epoch : 871 || Loss => 0.7954 || Accuracy => 0.9191\n",
      "----------------------\n",
      "Epoch : 872 || Loss => 0.7954 || Accuracy => 0.9191\n",
      "----------------------\n",
      "Epoch : 873 || Loss => 0.7954 || Accuracy => 0.9191\n",
      "----------------------\n",
      "Epoch : 874 || Loss => 0.7954 || Accuracy => 0.9191\n",
      "----------------------\n",
      "Epoch : 875 || Loss => 0.7954 || Accuracy => 0.9191\n",
      "----------------------\n",
      "Epoch : 876 || Loss => 0.7954 || Accuracy => 0.9191\n",
      "----------------------\n",
      "Epoch : 877 || Loss => 0.7954 || Accuracy => 0.9191\n",
      "----------------------\n",
      "Epoch : 878 || Loss => 0.7954 || Accuracy => 0.9191\n",
      "----------------------\n",
      "Epoch : 879 || Loss => 0.7954 || Accuracy => 0.9191\n",
      "----------------------\n",
      "Epoch : 880 || Loss => 0.7954 || Accuracy => 0.9191\n",
      "----------------------\n",
      "Epoch : 881 || Loss => 0.7954 || Accuracy => 0.9191\n",
      "----------------------\n",
      "Epoch : 882 || Loss => 0.7954 || Accuracy => 0.9191\n",
      "----------------------\n",
      "Epoch : 883 || Loss => 0.7954 || Accuracy => 0.9192\n",
      "----------------------\n",
      "Epoch : 884 || Loss => 0.7954 || Accuracy => 0.9191\n",
      "----------------------\n",
      "Epoch : 885 || Loss => 0.7954 || Accuracy => 0.9191\n",
      "----------------------\n",
      "Epoch : 886 || Loss => 0.7954 || Accuracy => 0.9191\n",
      "----------------------\n",
      "Epoch : 887 || Loss => 0.7954 || Accuracy => 0.9191\n",
      "----------------------\n",
      "Epoch : 888 || Loss => 0.7954 || Accuracy => 0.9191\n",
      "----------------------\n",
      "Epoch : 889 || Loss => 0.7954 || Accuracy => 0.9191\n",
      "----------------------\n",
      "Epoch : 890 || Loss => 0.7954 || Accuracy => 0.9191\n",
      "----------------------\n",
      "Epoch : 891 || Loss => 0.7954 || Accuracy => 0.9191\n",
      "----------------------\n",
      "Epoch : 892 || Loss => 0.7953 || Accuracy => 0.9191\n",
      "----------------------\n",
      "Epoch : 893 || Loss => 0.7953 || Accuracy => 0.9191\n",
      "----------------------\n",
      "Epoch : 894 || Loss => 0.7953 || Accuracy => 0.9191\n",
      "----------------------\n",
      "Epoch : 895 || Loss => 0.7953 || Accuracy => 0.9191\n",
      "----------------------\n",
      "Epoch : 896 || Loss => 0.7953 || Accuracy => 0.9191\n",
      "----------------------\n",
      "Epoch : 897 || Loss => 0.7953 || Accuracy => 0.9191\n",
      "----------------------\n",
      "Epoch : 898 || Loss => 0.7953 || Accuracy => 0.9191\n",
      "----------------------\n",
      "Epoch : 899 || Loss => 0.7953 || Accuracy => 0.9191\n",
      "----------------------\n",
      "Epoch : 900 || Loss => 0.7953 || Accuracy => 0.9191\n",
      "----------------------\n",
      "Epoch : 901 || Loss => 0.7953 || Accuracy => 0.9191\n",
      "----------------------\n",
      "Epoch : 902 || Loss => 0.7953 || Accuracy => 0.9191\n",
      "----------------------\n",
      "Epoch : 903 || Loss => 0.7953 || Accuracy => 0.9191\n",
      "----------------------\n",
      "Epoch : 904 || Loss => 0.7953 || Accuracy => 0.9191\n",
      "----------------------\n",
      "Epoch : 905 || Loss => 0.7953 || Accuracy => 0.9191\n",
      "----------------------\n",
      "Epoch : 906 || Loss => 0.7953 || Accuracy => 0.9191\n",
      "----------------------\n",
      "Epoch : 907 || Loss => 0.7953 || Accuracy => 0.9191\n",
      "----------------------\n",
      "Epoch : 908 || Loss => 0.7953 || Accuracy => 0.9191\n",
      "----------------------\n",
      "Epoch : 909 || Loss => 0.7953 || Accuracy => 0.9191\n",
      "----------------------\n",
      "Epoch : 910 || Loss => 0.7953 || Accuracy => 0.9191\n",
      "----------------------\n",
      "Epoch : 911 || Loss => 0.7953 || Accuracy => 0.9191\n",
      "----------------------\n",
      "Epoch : 912 || Loss => 0.7953 || Accuracy => 0.9191\n",
      "----------------------\n",
      "Epoch : 913 || Loss => 0.7953 || Accuracy => 0.9191\n",
      "----------------------\n",
      "Epoch : 914 || Loss => 0.7953 || Accuracy => 0.9191\n",
      "----------------------\n",
      "Epoch : 915 || Loss => 0.7953 || Accuracy => 0.9191\n",
      "----------------------\n",
      "Epoch : 916 || Loss => 0.7953 || Accuracy => 0.9191\n",
      "----------------------\n",
      "Epoch : 917 || Loss => 0.7953 || Accuracy => 0.9191\n",
      "----------------------\n",
      "Epoch : 918 || Loss => 0.7953 || Accuracy => 0.9191\n",
      "----------------------\n",
      "Epoch : 919 || Loss => 0.7953 || Accuracy => 0.9191\n",
      "----------------------\n",
      "Epoch : 920 || Loss => 0.7953 || Accuracy => 0.9191\n",
      "----------------------\n",
      "Epoch : 921 || Loss => 0.7953 || Accuracy => 0.9191\n",
      "----------------------\n",
      "Epoch : 922 || Loss => 0.7953 || Accuracy => 0.9191\n",
      "----------------------\n",
      "Epoch : 923 || Loss => 0.7953 || Accuracy => 0.9191\n",
      "----------------------\n",
      "Epoch : 924 || Loss => 0.7953 || Accuracy => 0.9191\n",
      "----------------------\n",
      "Epoch : 925 || Loss => 0.7953 || Accuracy => 0.9191\n",
      "----------------------\n",
      "Epoch : 926 || Loss => 0.7953 || Accuracy => 0.9191\n",
      "----------------------\n",
      "Epoch : 927 || Loss => 0.7953 || Accuracy => 0.9191\n",
      "----------------------\n",
      "Epoch : 928 || Loss => 0.7953 || Accuracy => 0.9191\n",
      "----------------------\n",
      "Epoch : 929 || Loss => 0.7953 || Accuracy => 0.9191\n",
      "----------------------\n",
      "Epoch : 930 || Loss => 0.7953 || Accuracy => 0.9191\n",
      "----------------------\n",
      "Epoch : 931 || Loss => 0.7953 || Accuracy => 0.9191\n",
      "----------------------\n",
      "Epoch : 932 || Loss => 0.7953 || Accuracy => 0.9191\n",
      "----------------------\n",
      "Epoch : 933 || Loss => 0.7953 || Accuracy => 0.9191\n",
      "----------------------\n",
      "Epoch : 934 || Loss => 0.7953 || Accuracy => 0.9191\n",
      "----------------------\n",
      "Epoch : 935 || Loss => 0.7953 || Accuracy => 0.9191\n",
      "----------------------\n",
      "Epoch : 936 || Loss => 0.7953 || Accuracy => 0.9191\n",
      "----------------------\n",
      "Epoch : 937 || Loss => 0.7953 || Accuracy => 0.9191\n",
      "----------------------\n",
      "Epoch : 938 || Loss => 0.7953 || Accuracy => 0.9192\n",
      "----------------------\n",
      "Epoch : 939 || Loss => 0.7953 || Accuracy => 0.9192\n",
      "----------------------\n",
      "Epoch : 940 || Loss => 0.7953 || Accuracy => 0.9192\n",
      "----------------------\n",
      "Epoch : 941 || Loss => 0.7953 || Accuracy => 0.9192\n",
      "----------------------\n",
      "Epoch : 942 || Loss => 0.7953 || Accuracy => 0.9192\n",
      "----------------------\n",
      "Epoch : 943 || Loss => 0.7953 || Accuracy => 0.9192\n",
      "----------------------\n",
      "Epoch : 944 || Loss => 0.7953 || Accuracy => 0.9192\n",
      "----------------------\n",
      "Epoch : 945 || Loss => 0.7953 || Accuracy => 0.9192\n",
      "----------------------\n",
      "Epoch : 946 || Loss => 0.7953 || Accuracy => 0.9192\n",
      "----------------------\n",
      "Epoch : 947 || Loss => 0.7953 || Accuracy => 0.9192\n",
      "----------------------\n",
      "Epoch : 948 || Loss => 0.7953 || Accuracy => 0.9192\n",
      "----------------------\n",
      "Epoch : 949 || Loss => 0.7953 || Accuracy => 0.9192\n",
      "----------------------\n",
      "Epoch : 950 || Loss => 0.7953 || Accuracy => 0.9192\n",
      "----------------------\n",
      "Epoch : 951 || Loss => 0.7953 || Accuracy => 0.9192\n",
      "----------------------\n",
      "Epoch : 952 || Loss => 0.7953 || Accuracy => 0.9192\n",
      "----------------------\n",
      "Epoch : 953 || Loss => 0.7953 || Accuracy => 0.9192\n",
      "----------------------\n",
      "Epoch : 954 || Loss => 0.7953 || Accuracy => 0.9192\n",
      "----------------------\n",
      "Epoch : 955 || Loss => 0.7953 || Accuracy => 0.9192\n",
      "----------------------\n",
      "Epoch : 956 || Loss => 0.7953 || Accuracy => 0.9192\n",
      "----------------------\n",
      "Epoch : 957 || Loss => 0.7953 || Accuracy => 0.9192\n",
      "----------------------\n",
      "Epoch : 958 || Loss => 0.7953 || Accuracy => 0.9192\n",
      "----------------------\n",
      "Epoch : 959 || Loss => 0.7953 || Accuracy => 0.9192\n",
      "----------------------\n",
      "Epoch : 960 || Loss => 0.7953 || Accuracy => 0.9192\n",
      "----------------------\n",
      "Epoch : 961 || Loss => 0.7953 || Accuracy => 0.9192\n",
      "----------------------\n",
      "Epoch : 962 || Loss => 0.7953 || Accuracy => 0.9192\n",
      "----------------------\n",
      "Epoch : 963 || Loss => 0.7953 || Accuracy => 0.9192\n",
      "----------------------\n",
      "Epoch : 964 || Loss => 0.7953 || Accuracy => 0.9192\n",
      "----------------------\n",
      "Epoch : 965 || Loss => 0.7953 || Accuracy => 0.9192\n",
      "----------------------\n",
      "Epoch : 966 || Loss => 0.7952 || Accuracy => 0.9192\n",
      "----------------------\n",
      "Epoch : 967 || Loss => 0.7952 || Accuracy => 0.9192\n",
      "----------------------\n",
      "Epoch : 968 || Loss => 0.7952 || Accuracy => 0.9192\n",
      "----------------------\n",
      "Epoch : 969 || Loss => 0.7952 || Accuracy => 0.9192\n",
      "----------------------\n",
      "Epoch : 970 || Loss => 0.7952 || Accuracy => 0.9192\n",
      "----------------------\n",
      "Epoch : 971 || Loss => 0.7952 || Accuracy => 0.9192\n",
      "----------------------\n",
      "Epoch : 972 || Loss => 0.7952 || Accuracy => 0.9192\n",
      "----------------------\n",
      "Epoch : 973 || Loss => 0.7952 || Accuracy => 0.9192\n",
      "----------------------\n",
      "Epoch : 974 || Loss => 0.7952 || Accuracy => 0.9192\n",
      "----------------------\n",
      "Epoch : 975 || Loss => 0.7952 || Accuracy => 0.9192\n",
      "----------------------\n",
      "Epoch : 976 || Loss => 0.7952 || Accuracy => 0.9192\n",
      "----------------------\n",
      "Epoch : 977 || Loss => 0.7952 || Accuracy => 0.9192\n",
      "----------------------\n",
      "Epoch : 978 || Loss => 0.7952 || Accuracy => 0.9192\n",
      "----------------------\n",
      "Epoch : 979 || Loss => 0.7952 || Accuracy => 0.9192\n",
      "----------------------\n",
      "Epoch : 980 || Loss => 0.7952 || Accuracy => 0.9192\n",
      "----------------------\n",
      "Epoch : 981 || Loss => 0.7952 || Accuracy => 0.9192\n",
      "----------------------\n",
      "Epoch : 982 || Loss => 0.7952 || Accuracy => 0.9192\n",
      "----------------------\n",
      "Epoch : 983 || Loss => 0.7952 || Accuracy => 0.9192\n",
      "----------------------\n",
      "Epoch : 984 || Loss => 0.7952 || Accuracy => 0.9192\n",
      "----------------------\n",
      "Epoch : 985 || Loss => 0.7952 || Accuracy => 0.9192\n",
      "----------------------\n",
      "Epoch : 986 || Loss => 0.7952 || Accuracy => 0.9192\n",
      "----------------------\n",
      "Epoch : 987 || Loss => 0.7952 || Accuracy => 0.9192\n",
      "----------------------\n",
      "Epoch : 988 || Loss => 0.7952 || Accuracy => 0.9192\n",
      "----------------------\n",
      "Epoch : 989 || Loss => 0.7952 || Accuracy => 0.9192\n",
      "----------------------\n",
      "Epoch : 990 || Loss => 0.7952 || Accuracy => 0.9192\n",
      "----------------------\n",
      "Epoch : 991 || Loss => 0.7952 || Accuracy => 0.9192\n",
      "----------------------\n",
      "Epoch : 992 || Loss => 0.7952 || Accuracy => 0.9192\n",
      "----------------------\n",
      "Epoch : 993 || Loss => 0.7952 || Accuracy => 0.9192\n",
      "----------------------\n",
      "Epoch : 994 || Loss => 0.7952 || Accuracy => 0.9192\n",
      "----------------------\n",
      "Epoch : 995 || Loss => 0.7952 || Accuracy => 0.9192\n",
      "----------------------\n",
      "Epoch : 996 || Loss => 0.7952 || Accuracy => 0.9192\n",
      "----------------------\n",
      "Epoch : 997 || Loss => 0.7952 || Accuracy => 0.9192\n",
      "----------------------\n",
      "Epoch : 998 || Loss => 0.7952 || Accuracy => 0.9192\n",
      "----------------------\n",
      "Epoch : 999 || Loss => 0.7952 || Accuracy => 0.9192\n",
      "----------------------\n",
      "Epoch : 1000 || Loss => 0.7952 || Accuracy => 0.9192\n",
      "----------------------\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Logistic' object has no attribute 'one_hot_encode'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 14\u001b[0m\n\u001b[0;32m     12\u001b[0m model \u001b[38;5;241m=\u001b[39m Logistic(train_images,train_labels,\u001b[38;5;241m1000\u001b[39m,\u001b[38;5;241m0.001\u001b[39m)\n\u001b[0;32m     13\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain_stochastic()\n\u001b[1;32m---> 14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest Accuracy: \u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_accuracy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtest_labels\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     16\u001b[0m model_batch \u001b[38;5;241m=\u001b[39m Logistic(train_images,train_labels,\u001b[38;5;241m1000\u001b[39m,\u001b[38;5;241m0.001\u001b[39m)\n\u001b[0;32m     17\u001b[0m model_batch\u001b[38;5;241m.\u001b[39mtrain()\n",
      "Cell \u001b[1;32mIn[3], line 97\u001b[0m, in \u001b[0;36mLogistic.test_accuracy\u001b[1;34m(self, X_test, Y_test)\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtest_accuracy\u001b[39m(\u001b[38;5;28mself\u001b[39m, X_test, Y_test):\n\u001b[1;32m---> 97\u001b[0m     Y_test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mone_hot_encode\u001b[49m(Y_test)\n\u001b[0;32m     98\u001b[0m     activation \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msoftmax(np\u001b[38;5;241m.\u001b[39mdot(X_test, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mWeights) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mBias)\n\u001b[0;32m     99\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(activation, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Logistic' object has no attribute 'one_hot_encode'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "\n",
    "# Load MNIST data\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "train_images = train_images.reshape((60000, 28 * 28))\n",
    "train_images = train_images.astype('float32') / 255\n",
    "\n",
    "test_images = test_images.reshape((10000, 28 * 28))\n",
    "test_images = test_images.astype('float32') / 255\n",
    "model = Logistic(train_images,train_labels,1000,0.001)\n",
    "model.train_stochastic()\n",
    "print(\"Test Accuracy: \",model.test_accuracy(test_images,test_labels))\n",
    "\n",
    "model_batch = Logistic(train_images,train_labels,1000,0.001)\n",
    "model_batch.train()\n",
    "print(\"Test Accuracy: \",model_batch.test_accuracy(test_images,test_labels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
